{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "modul_ucd.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1D_Q4akInoIY",
        "RkW-XQc8nYfJ",
        "QcODID7GGsG5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !pip install -U pywsd\r\n",
        "# !pip install -U wn==0.0.23\r\n",
        "# !pip install XlsxWriter"
      ],
      "outputs": [],
      "metadata": {
        "id": "4pbz2pC4L1si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modul1: xmlparser"
      ],
      "metadata": {
        "id": "3LbIYvnsxNiA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# function\r\n",
        "import os\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import pandas as pd\r\n",
        "from tabulate import tabulate\r\n",
        "\r\n",
        "# template class xmlparser\r\n",
        "class xmlParser:\r\n",
        "\r\n",
        "    # inisialisasi\r\n",
        "    def __init__(self, filename= 'IRCI_Researcher.xmi', \r\n",
        "                 tipe_xmi= '{http://schema.omg.org/spec/XMI/2.1}type',\r\n",
        "                 id_xmi= '{http://schema.omg.org/spec/XMI/2.1}id'):\r\n",
        "    \tself.namaFile = filename\r\n",
        "    \tself.xmi_type = tipe_xmi\r\n",
        "    \tself.xmi_id = id_xmi\r\n",
        "\r\n",
        "    #fungsi parse tree elemen\r\n",
        "    def elemenTreeParse(self):\r\n",
        "      tree = ET.parse(self.namaFile)\r\n",
        "      root = tree.getroot()\r\n",
        "      try: \r\n",
        "        elemenTag = [elem.tag for elem in root.iter()]\r\n",
        "        elemenAtribut = [elem.attrib for elem in root.iter()]\r\n",
        "        tabelElemen = pd.DataFrame([elemenTag, elemenAtribut], index=['Berdasarkan Tag', 'Berdsarkan Atribut']).T\r\n",
        "        return tabelElemen\r\n",
        "\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    # fungsi pencarian elemen\r\n",
        "    def cariTreeElemen(self, elemen):\r\n",
        "      try:\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root1 = tree1.getroot()\r\n",
        "        pencarian = [num.findall(elemen) for num in root1.iter()]\r\n",
        "        return pencarian\r\n",
        "\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    #fungsi list elemen\r\n",
        "    def listElemen(self, elemen):\r\n",
        "      try:\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        listElemen = [berdasarkanOwnEnd.attrib for berdasarkanOwnEnd in root.iter(elemen)]\r\n",
        "        tabelElement = pd.DataFrame(listElemen)\r\n",
        "        return tabelElement\r\n",
        "\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    # fungsi mencari table spesifik\r\n",
        "    def tableElemenSpesifik(self, elemen= 'packagedElement', kolom1= 'name'):\r\n",
        "      try:\r\n",
        "        hasil = []\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        berdasarkanPackagedELement = [packagedElement.attrib for packagedElement in root.iter(elemen)]\r\n",
        "        for num in berdasarkanPackagedELement:\r\n",
        "          a1 = num[kolom1]\r\n",
        "          c1 = num[self.xmi_type]\r\n",
        "          d1 = num[self.xmi_id]\r\n",
        "          hasil.append([a1, c1, d1])\r\n",
        "        cleanPackagedELement = pd.DataFrame(hasil, columns=[kolom1, self.xmi_type, self.xmi_id])\r\n",
        "        return cleanPackagedELement\r\n",
        "        \r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "\r\n",
        "    # fungsi mencari string\r\n",
        "    def doString(self):\r\n",
        "      try:\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        print(ET.tostring(root, encoding='utf8').decode('utf8'))\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "\r\n",
        "    def dataPaketElemen(self, category = 'packagedElement'):\r\n",
        "      try:\r\n",
        "        hasil = []\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        berdasarkanPackagedELement = [packagedElement.attrib for packagedElement in root.iter(category)]\r\n",
        "        for num in berdasarkanPackagedELement:\r\n",
        "          a1 = num[self.xmi_id]\r\n",
        "          b1 = num['name']\r\n",
        "          d1 = num[self.xmi_type]\r\n",
        "          hasil.append([a1, b1, d1])\r\n",
        "\r\n",
        "        paketElemen = pd.DataFrame(hasil, columns=['id', 'name', 'type'])\r\n",
        "        return paketElemen\r\n",
        "\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    def dataExtend(self, category = 'extend'):\r\n",
        "      try:\r\n",
        "        hasil = []\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        berdasarkanExtend = [packagedElement.attrib for packagedElement in root.iter(category)]\r\n",
        "        for num in berdasarkanExtend:\r\n",
        "          a1 = num[self.xmi_id]\r\n",
        "          b1 = num[self.xmi_type]\r\n",
        "          c1 = num['extendedCase']\r\n",
        "          d1 = paketElemen[paketElemen['id'] == c1].iloc[0]['name']\r\n",
        "          e1 = num['extension']\r\n",
        "          f1 = paketElemen[paketElemen['id'] == e1].iloc[0]['name']\r\n",
        "          hasil.append([a1, b1, c1, d1, e1, f1])\r\n",
        "          \r\n",
        "        extendTable = pd.DataFrame(hasil, columns=['id', 'type', 'source', 'sourceName', 'destination', 'destinationName'])\r\n",
        "        return extendTable\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    def dataOwnedEnd(self, category = 'ownedEnd'):\r\n",
        "      try:\r\n",
        "        # berdasarkan ownedEnd\r\n",
        "        hasil = []\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        berdasarkanOwnedEnd = [packagedElement.attrib for packagedElement in root.iter(category)]\r\n",
        "        berdasarkanOwnedEnd\r\n",
        "        for num in berdasarkanOwnedEnd:\r\n",
        "          a1 = num['type']\r\n",
        "          b1 = num[self.xmi_id]\r\n",
        "          c1 = num[self.xmi_type]\r\n",
        "          d1 = paketElemen[paketElemen['id'] == a1].iloc[0]['name']\r\n",
        "          hasil.append([a1, b1, c1, d1])\r\n",
        "          \r\n",
        "        ownedEndTable = pd.DataFrame(hasil, columns=['id_data', 'id_property', 'type_property', 'id_name'])\r\n",
        "        return ownedEndTable\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "\r\n",
        "    def dataOwnedMember(self, category = 'ownedMember'):\r\n",
        "      try:\r\n",
        "        # berdasarkan UML Model\r\n",
        "        hasilNum = []\r\n",
        "        tree1 = ET.parse(self.namaFile)\r\n",
        "        root = tree1.getroot()\r\n",
        "        berdasarkanOwnedMember = [packagedElement for packagedElement in root.iter(category)]\r\n",
        "        for num in berdasarkanOwnedMember:\r\n",
        "          a = num.attrib[self.xmi_id]\r\n",
        "          b = num.attrib[self.xmi_type]\r\n",
        "          for index, angka in enumerate(num.iter('ownedEnd')):\r\n",
        "            if index == 0:\r\n",
        "              c = paketElemen[paketElemen['id'] == angka.attrib['type']].iloc[0]['name']\r\n",
        "            else:\r\n",
        "              d = paketElemen[paketElemen['id'] == angka.attrib['type']].iloc[0]['name']\r\n",
        "          hasilNum.append([a, b, c, d])\r\n",
        "\r\n",
        "        ownedMemberTable = pd.DataFrame(hasilNum, columns=['id', 'type_property', 'actor', 'usecase'])\r\n",
        "        return ownedMemberTable  \r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    def __del__(self):\r\n",
        "        print ('Destructor called.')    \r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  try:\r\n",
        "      # myXmlParser = xmlParser(filename= '/content/mydrive/MyDrive/dataset/IRCI_V2/topic/IRCI_Topic.xmi')\r\n",
        "      # myXmlParser = xmlParser(filename= '/content/mydrive/MyDrive/dataset/IRCI_V2/researcher/IRCI_Researcher.xmi')\r\n",
        "      myXmlParser = xmlParser()\r\n",
        "      paketElemen = myXmlParser.dataPaketElemen()\r\n",
        "      extendTable = myXmlParser.dataExtend()\r\n",
        "      ownedEndTable = myXmlParser.dataOwnedEnd()\r\n",
        "      ownedMemberTable = myXmlParser.dataOwnedMember()\r\n",
        "  \r\n",
        "      \"\"\"# Modul 1\r\n",
        "      Parsing file xmi menjadi tabel2 (daftar aktor, daftar use case, dan relasi antara actor use case dan antar use case)\r\n",
        "      \"\"\"\r\n",
        "      print(\"actorTable\")\r\n",
        "      actorTable = paketElemen[paketElemen['type'] == 'uml:Actor']\r\n",
        "      print(tabulate(actorTable, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      print(\"\\nuseCaseTable\")\r\n",
        "      useCaseTable = paketElemen[paketElemen['type'] == 'uml:UseCase']\r\n",
        "      print(tabulate(useCaseTable, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      print(\"\\nextendTable\")\r\n",
        "      print(tabulate(extendTable, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      print(\"\\nassociationTable\")\r\n",
        "      print(tabulate(ownedMemberTable, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      print(\"\\npropertyTable\")\r\n",
        "      print(tabulate(ownedEndTable, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      hasilAktor = []\r\n",
        "      hasilDestinasi = []\r\n",
        "\r\n",
        "      for idx, num in enumerate(extendTable.sourceName):\r\n",
        "        c = ownedMemberTable[ownedMemberTable['usecase'] == extendTable.sourceName[idx]]\r\n",
        "        if len(c) > 0:\r\n",
        "          for aktor in c.actor:\r\n",
        "            hasilAktor.append(aktor)\r\n",
        "            hasilDestinasi.append(extendTable.destinationName[idx])\r\n",
        "        else:\r\n",
        "          temp = 1\r\n",
        "          d = ownedMemberTable[ownedMemberTable['usecase'] == extendTable.sourceName[idx-temp]]\r\n",
        "          for dAktor in d.actor:\r\n",
        "            hasilAktor.append(dAktor)\r\n",
        "            hasilDestinasi.append(extendTable.destinationName[idx])\r\n",
        "\r\n",
        "      df_a = pd.DataFrame([hasilAktor, hasilDestinasi], index= ['actor', 'action']).T\r\n",
        "      df_a['actor'] = df_a.groupby(['action'])['actor'].transform(lambda x: ';'.join(x))\r\n",
        "      df_a = df_a[['action','actor']].drop_duplicates()\r\n",
        "      df_a['actor'][2] = set(df_a['actor'][2].split(\";\")) # fungsi ini digunakan untuk menyempurnakan format\r\n",
        "      df_a['actor'][2] = \";\".join(df_a['actor'][2])\r\n",
        "      print(\"\\nactorActionTable\")\r\n",
        "      print(tabulate(df_a, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      myXmlParser.__del__()\r\n",
        "\r\n",
        "  except OSError as err:\r\n",
        "      print(\"OS error: {0}\".format(err))\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actorTable\n",
            "+----+----------------------+-----------+-----------+\n",
            "|    | id                   | name      | type      |\n",
            "|----+----------------------+-----------+-----------|\n",
            "|  1 | AAAAAAF4mi7mgDh1TSM= | Submitter | uml:Actor |\n",
            "|  4 | AAAAAAF4mi99ijj8BCY= | Viewer    | uml:Actor |\n",
            "+----+----------------------+-----------+-----------+\n",
            "\n",
            "useCaseTable\n",
            "+----+----------------------+------------------------+-------------+\n",
            "|    | id                   | name                   | type        |\n",
            "|----+----------------------+------------------------+-------------|\n",
            "|  2 | AAAAAAF4mi8PyDifi1c= | insertMetadata         | uml:UseCase |\n",
            "|  3 | AAAAAAF4mi8ydjjN568= | searchResearcher       | uml:UseCase |\n",
            "|  5 | AAAAAAF4mjIw1zvIN8o= | searchArticle          | uml:UseCase |\n",
            "|  6 | AAAAAAF4mjJ07jyH6c4= | viewNextResult         | uml:UseCase |\n",
            "|  7 | AAAAAAF4mjPvZT9ass0= | orderByRelevancy       | uml:UseCase |\n",
            "|  8 | AAAAAAF4mjRfaEAQ9os= | orderByScore           | uml:UseCase |\n",
            "|  9 | AAAAAAF4mjS6/EDYTk8= | viewDetailOfResearcher | uml:UseCase |\n",
            "| 10 | AAAAAAF4mjURoUGOMMc= | editProfile            | uml:UseCase |\n",
            "| 11 | AAAAAAF4mjVMjEPi+Lg= | removeArticle          | uml:UseCase |\n",
            "+----+----------------------+------------------------+-------------+\n",
            "\n",
            "extendTable\n",
            "+----+----------------------+------------+----------------------+------------------------+----------------------+------------------------+\n",
            "|    | id                   | type       | source               | sourceName             | destination          | destinationName        |\n",
            "|----+----------------------+------------+----------------------+------------------------+----------------------+------------------------|\n",
            "|  0 | AAAAAAF4mjK8bj1PVZQ= | uml:Extend | AAAAAAF4mi8PyDifi1c= | insertMetadata         | AAAAAAF4mjIw1zvIN8o= | searchArticle          |\n",
            "|  1 | AAAAAAF4mjMMwD4V6+M= | uml:Extend | AAAAAAF4mi8PyDifi1c= | insertMetadata         | AAAAAAF4mjIw1zvIN8o= | searchArticle          |\n",
            "|  2 | AAAAAAF4mjNY8D6c2V4= | uml:Extend | AAAAAAF4mjIw1zvIN8o= | searchArticle          | AAAAAAF4mjJ07jyH6c4= | viewNextResult         |\n",
            "|  3 | AAAAAAF4mjXE8EYDP8I= | uml:Extend | AAAAAAF4mi8ydjjN568= | searchResearcher       | AAAAAAF4mjPvZT9ass0= | orderByRelevancy       |\n",
            "|  4 | AAAAAAF4mjXqS0Z4De0= | uml:Extend | AAAAAAF4mi8ydjjN568= | searchResearcher       | AAAAAAF4mjRfaEAQ9os= | orderByScore           |\n",
            "|  5 | AAAAAAF4mjZD3EjDQ6w= | uml:Extend | AAAAAAF4mi8ydjjN568= | searchResearcher       | AAAAAAF4mjS6/EDYTk8= | viewDetailOfResearcher |\n",
            "|  6 | AAAAAAF4mjcNv0mI9L0= | uml:Extend | AAAAAAF4mjS6/EDYTk8= | viewDetailOfResearcher | AAAAAAF4mjURoUGOMMc= | editProfile            |\n",
            "|  7 | AAAAAAF4mjbxIUlKgbk= | uml:Extend | AAAAAAF4mjS6/EDYTk8= | viewDetailOfResearcher | AAAAAAF4mjVMjEPi+Lg= | removeArticle          |\n",
            "+----+----------------------+------------+----------------------+------------------------+----------------------+------------------------+\n",
            "\n",
            "associationTable\n",
            "+----+----------------------+-----------------+-----------+------------------+\n",
            "|    | id                   | type_property   | actor     | usecase          |\n",
            "|----+----------------------+-----------------+-----------+------------------|\n",
            "|  0 | AAAAAAF4mjEd2znxW70= | uml:Association | Submitter | insertMetadata   |\n",
            "|  1 | AAAAAAF4mjFZVDo6ugo= | uml:Association | Submitter | searchResearcher |\n",
            "|  2 | AAAAAAF4mjGFvTqMa1Y= | uml:Association | Viewer    | searchResearcher |\n",
            "+----+----------------------+-----------------+-----------+------------------+\n",
            "\n",
            "propertyTable\n",
            "+----+----------------------+----------------------+-----------------+------------------+\n",
            "|    | id_data              | id_property          | type_property   | id_name          |\n",
            "|----+----------------------+----------------------+-----------------+------------------|\n",
            "|  0 | AAAAAAF4mi7mgDh1TSM= | AAAAAAF4mjEd2znyn70= | uml:Property    | Submitter        |\n",
            "|  1 | AAAAAAF4mi8PyDifi1c= | AAAAAAF4mjEd2znz9JY= | uml:Property    | insertMetadata   |\n",
            "|  2 | AAAAAAF4mi7mgDh1TSM= | AAAAAAF4mjFZVDo7nEA= | uml:Property    | Submitter        |\n",
            "|  3 | AAAAAAF4mi8ydjjN568= | AAAAAAF4mjFZVDo8Jp8= | uml:Property    | searchResearcher |\n",
            "|  4 | AAAAAAF4mi99ijj8BCY= | AAAAAAF4mjGFvTqNVrk= | uml:Property    | Viewer           |\n",
            "|  5 | AAAAAAF4mi8ydjjN568= | AAAAAAF4mjGFvTqOglI= | uml:Property    | searchResearcher |\n",
            "+----+----------------------+----------------------+-----------------+------------------+\n",
            "\n",
            "actorActionTable\n",
            "+----+------------------------+---------------------+\n",
            "|    | action                 | actor               |\n",
            "|----+------------------------+---------------------|\n",
            "|  0 | searchArticle          | Submitter;Submitter |\n",
            "|  2 | viewNextResult         | Submitter           |\n",
            "|  3 | orderByRelevancy       | Submitter;Viewer    |\n",
            "|  5 | orderByScore           | Submitter;Viewer    |\n",
            "|  7 | viewDetailOfResearcher | Submitter;Viewer    |\n",
            "|  9 | editProfile            | Submitter;Viewer    |\n",
            "+----+------------------------+---------------------+\n",
            "Destructor called.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ADmce0anTnm",
        "outputId": "af5a24ec-c597-43f3-8443-830a3b937896"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import xlsxwriter\r\n",
        "import pandas as pd\r\n",
        "dfs  = {\r\n",
        "          'tabel_aktor' : actorTable, \r\n",
        "          'tabel_usecase' : useCaseTable,\r\n",
        "          'tabel_relasi' : extendTable,\r\n",
        "          'tabel_asosisasi' : ownedMemberTable,\r\n",
        "          'tabel_properti' : ownedEndTable,\r\n",
        "          'tabel_aktor_action' : df_a,\r\n",
        "        } \r\n",
        "\r\n",
        "writer = pd.ExcelWriter('/data/data_xmi.xlsx')\r\n",
        "\r\n",
        "for name,dataframe in dfs.items():\r\n",
        "    dataframe.to_excel(writer,name,index=False)\r\n",
        "\r\n",
        "writer.save()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xesxursq2LCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modul2: parsing aksi dan aktor"
      ],
      "metadata": {
        "id": "1D_Q4akInoIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\r\n",
        "import nltk\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize \r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "from tabulate import tabulate\r\n",
        "\r\n",
        "# nltk.download('stopwords')\r\n",
        "# nltk.download('punkt')\r\n",
        "# nltk.download('wordnet')\r\n",
        "# nltk.download('averaged_perceptron_tagger')\r\n",
        "\r\n",
        "stemming = PorterStemmer()\r\n",
        "stops = set(stopwords.words(\"english\"))\r\n",
        "lem = WordNetLemmatizer()\r\n",
        "\r\n",
        "\r\n",
        "# template class parsingRequirement\r\n",
        "class parsingRequirement:\r\n",
        "\r\n",
        "    # inisialisasi\r\n",
        "    def __init__(self, filename):\r\n",
        "    \tself.namaFile = filename\r\n",
        "      \r\n",
        "    #fungsi parse tree elemen\r\n",
        "    def membacaCSV(self):\r\n",
        "      try: \r\n",
        "        modul_pembacaan = pd.read_csv(self.namaFile, delimiter= ',')\r\n",
        "        return modul_pembacaan\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    # cleaning text\r\n",
        "    def apply_cleaning_function_to_list(self, X):\r\n",
        "      try:\r\n",
        "        cleaned_X = []\r\n",
        "        for element in X:\r\n",
        "            cleaned_X.append(parsingRequirement.clean_text(self, raw_text= element))\r\n",
        "        return cleaned_X\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "    def clean_text(self, raw_text):\r\n",
        "      try:\r\n",
        "        text = raw_text.lower()\r\n",
        "        tokens = word_tokenize(text)\r\n",
        "        token_words = [w for w in tokens if w.isalpha()]\r\n",
        "        lemma_words = [lem.lemmatize(w) for w in token_words]\r\n",
        "        meaningful_words = [w for w in lemma_words if not w in stops]\r\n",
        "        joined_words = ( \" \".join(meaningful_words))\r\n",
        "        return joined_words\r\n",
        "      except OSError as err:\r\n",
        "        print(\"OS error: {0}\".format(err))\r\n",
        "\r\n",
        "\r\n",
        "    def __del__(self):\r\n",
        "        print ('Destructor called.')\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  try:\r\n",
        "\r\n",
        "    # parsing functional\r\n",
        "    MyParsingRequirement = parsingRequirement(filename= \"freqs_researcher.txt\")\r\n",
        "    freqs = MyParsingRequirement.membacaCSV()\r\n",
        "\r\n",
        "    # pembersihan data\r\n",
        "    freq_requirement = freqs.requirement\r\n",
        "    id_freq_requirement = freqs.id\r\n",
        "    text_to_clean_freq = list(freq_requirement)\r\n",
        "    cleaned_freq = MyParsingRequirement.apply_cleaning_function_to_list(text_to_clean_freq)\r\n",
        "\r\n",
        "    data_aktor = []\r\n",
        "    data_aksi = []\r\n",
        "    for num in cleaned_freq:\r\n",
        "      a = (word_tokenize(num))\r\n",
        "      b = [x for x in a if x == 'submitter' or x == 'system']  \r\n",
        "      b1 = \" \".join(b)\r\n",
        "      data_aktor.append(b1)\r\n",
        "      c = [x for x in a if x != 'submitter' and x != 'system']  \r\n",
        "      c1 = \" \".join(c)\r\n",
        "      data_aksi.append(c1)\r\n",
        "\r\n",
        "    freqs['aksi'] = data_aksi\r\n",
        "    freqs['aktor'] = data_aktor\r\n",
        "    print(\"\\nfreqs\")\r\n",
        "    print(tabulate(freqs, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "    # parsing ucd1\r\n",
        "    MyParsingRequirement = parsingRequirement(filename= \"insert_metadata.txt\")\r\n",
        "    ucd1 = MyParsingRequirement.membacaCSV()\r\n",
        "    data_ucd1 = []\r\n",
        "    for num in ucd1.flowOfEvents.fillna(\"empty\"):\r\n",
        "      for num1 in num.split(\";\"):\r\n",
        "        for num2 in num1.split(\".\"):\r\n",
        "          if 'Submitter' in num2:\r\n",
        "            data_ucd1.append(num2)\r\n",
        "          elif 'system' in num2:\r\n",
        "            data_ucd1.append(num2)\r\n",
        "          elif 'empty' in num2:\r\n",
        "            data_ucd1.append(num2)\r\n",
        "\r\n",
        "    list_index= [(\"data{}\".format(idx)) for idx, num in enumerate(data_ucd1)]\r\n",
        "    data_list = pd.DataFrame(data_ucd1, index= list_index)\r\n",
        "    data_list = data_list.drop(index= \"data5\").reset_index().drop(labels= ['index'], axis= 1)\r\n",
        "    ucd1['aksi'] = data_list\r\n",
        "    ucd1\r\n",
        "\r\n",
        "    ucd1_req = ucd1.aksi\r\n",
        "    id_ucd1_req = ucd1.id\r\n",
        "    text_to_clean_freq = list(ucd1_req)\r\n",
        "    cleaned1_ucd = MyParsingRequirement.apply_cleaning_function_to_list(text_to_clean_freq)\r\n",
        "\r\n",
        "    data_aktor = []\r\n",
        "    data_aksi = []\r\n",
        "    for num in cleaned1_ucd:\r\n",
        "      a = (word_tokenize(num))\r\n",
        "      b = [x for x in a if x == 'submitter' or x == 'system']  \r\n",
        "      b1 = \" \".join(b)\r\n",
        "      data_aktor.append(b1)\r\n",
        "      c = [x for x in a if x != 'submitter' and x != 'system']  \r\n",
        "      c1 = \" \".join(c)\r\n",
        "      data_aksi.append(c1)\r\n",
        "\r\n",
        "    ucd1['aksi'] = data_aksi\r\n",
        "    ucd1['aktor'] = data_aktor\r\n",
        "    print(\"\\nucd1\")\r\n",
        "    print(tabulate(ucd1, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "    # parsing ucd2\r\n",
        "    MyParsingRequirement = parsingRequirement(filename= \"search_researcher.txt\")\r\n",
        "    ucd2 = MyParsingRequirement.membacaCSV()\r\n",
        "\r\n",
        "    #variable\r\n",
        "    data_ucd2 = []\r\n",
        "    for num in ucd2.flowOfEvents.fillna(\"empty\"):\r\n",
        "      for num1 in num.split(\";\"):\r\n",
        "        for num2 in num1.split(\".\"):\r\n",
        "          if 'Submitter' in num2:\r\n",
        "            data_ucd2.append(num2)\r\n",
        "          elif 'system' in num2:\r\n",
        "            data_ucd2.append(num2)\r\n",
        "          elif 'actor' in num2:\r\n",
        "            data_ucd2.append(num2)\r\n",
        "          elif 'empty' in num2:\r\n",
        "            data_ucd2.append(num2)\r\n",
        "\r\n",
        "    list2_index= [(\"data{}\".format(idx)) for idx, num in enumerate(data_ucd2)]\r\n",
        "    data2_list = pd.DataFrame(data_ucd2, index= list2_index)\r\n",
        "    data2_list = data2_list.reset_index().drop(labels= ['index'], axis= 1)\r\n",
        "    ucd2['aksi'] = data2_list\r\n",
        "\r\n",
        "    ucd2_req = ucd2.aksi\r\n",
        "    id_ucd2_req = ucd2.id\r\n",
        "    text_to_clean_freq = list(ucd2_req)\r\n",
        "    cleaned2_ucd = MyParsingRequirement.apply_cleaning_function_to_list(text_to_clean_freq)\r\n",
        "\r\n",
        "    data2_aktor = []\r\n",
        "    data2_aksi = []\r\n",
        "    for num in cleaned2_ucd:\r\n",
        "      a = (word_tokenize(num))\r\n",
        "      b = [x for x in a if x == 'submitter' or x == 'system' or x == 'actor']  \r\n",
        "      b1 = \" \".join(b)\r\n",
        "      b1 = b1.replace(\"actor\", \"submitter; viewer\")\r\n",
        "      data2_aktor.append(b1)\r\n",
        "      c = [x for x in a if x != 'submitter' and x != 'system' and x != 'actor']  \r\n",
        "      c1 = \" \".join(c)\r\n",
        "      data2_aksi.append(c1)\r\n",
        "\r\n",
        "    ucd2['aksi'] = data2_aksi\r\n",
        "    ucd2['aktor'] = data2_aktor\r\n",
        "    ucd2\r\n",
        "\r\n",
        "    print(\"\\nucd2\")\r\n",
        "    print(tabulate(ucd2, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "  except OSError as err:\r\n",
        "      print(\"OS error: {0}\".format(err))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "freqs\n",
            "+----+------+---------------------------------------------------------------------------+--------------------------------------------+-----------+\n",
            "|    | id   | requirement                                                               | aksi                                       | aktor     |\n",
            "|----+------+---------------------------------------------------------------------------+--------------------------------------------+-----------|\n",
            "|  0 | F01  | Submitter can insert metadata of article                                  | insert metadata article                    | submitter |\n",
            "|  1 | F02  | Submitter or Viewer can search researchers which are relevant to keyword  | viewer search researcher relevant keyword  | submitter |\n",
            "|  2 | F03  | Submitter or Viewer can sort the researchers start from the highest score | viewer sort researcher start highest score | submitter |\n",
            "|  3 | F04  | Submitter or Viewer can sort the article starts from the relevancy        | viewer sort article start relevancy        | submitter |\n",
            "|  4 | F05  | Submitter or viewer can view the detail of a researcher profile           | viewer view detail researcher profile      | submitter |\n",
            "|  5 | F06  | Submitter can remove an article from his/her profile                      | remove article profile                     | submitter |\n",
            "|  6 | F07  | Submitter can edit his/ her profile                                       | edit profile                               | submitter |\n",
            "|  7 | F08  | The system can show a progress bar                                        | show progress bar                          | system    |\n",
            "+----+------+---------------------------------------------------------------------------+--------------------------------------------+-----------+\n",
            "Destructor called.\n",
            "\n",
            "ucd1\n",
            "+----+-------------------+----------------+---------------------------------------------------------------------------------------------------------------------+----------------------------------------------------+-----------+\n",
            "|    | id                | usecase        | flowOfEvents                                                                                                        | aksi                                               | aktor     |\n",
            "|----+-------------------+----------------+---------------------------------------------------------------------------------------------------------------------+----------------------------------------------------+-----------|\n",
            "|  0 | basic_flow        | nan            | nan                                                                                                                 | empty                                              |           |\n",
            "|  1 | 1                 | insertMetadata | In the main page; Submitter clicks on insert metadata menu.                                                         | click insert metadata menu                         | submitter |\n",
            "|  2 | 2                 | insertMetadata | The system shows a form for inserting metadata.                                                                     | show form inserting metadata                       | system    |\n",
            "|  3 | 3                 | insertMetadata | Submitter fills in the metadata field with metadata of article(s); then clicks on submit button.                    | fill metadata field metadata article               | submitter |\n",
            "|  4 | 4                 | insertMetadata | The system shows the progress information. After it is done; the system shows a message: “Submission is completed.” | show progress information                          | system    |\n",
            "|  5 | 5                 | insertMetadata | The system returns to the main page.                                                                                | return main page                                   | system    |\n",
            "|  6 | alternative_flows | nan            | nan                                                                                                                 | empty                                              |           |\n",
            "|  7 | extensionPoints   | nan            | nan                                                                                                                 | empty                                              |           |\n",
            "|  8 | 3b                | searchArticle  | Submitter can add metadata by Search an existing Article based on a keyword.                                        | add metadata search existing article based keyword | submitter |\n",
            "|  9 | 3b.1              | searchArticle  | Submitter enter a keyword and clicks Search Article button.                                                         | enter keyword click search article button          | submitter |\n",
            "| 10 | 3b.2              | searchArticle  | The system shows the progress information. After it is done it shows a result (a list of relevant articles).        | show progress information                          | system    |\n",
            "| 11 | 3b.4              | searchArticle  | Submitter click an Add button on a relevant article.                                                                | click add button relevant article                  | submitter |\n",
            "| 12 | 3b.5              | searchArticle  | The system shows the metadata of the relevant article.                                                              | show metadata relevant article                     | system    |\n",
            "| 13 | 3b.2a             | viewNextResult | The Submitter can View to the Nextpage of the Result.                                                               | view nextpage result                               | submitter |\n",
            "| 14 | 4b.2a.1           | viewNextResult | The Submitter clicks on Next button to move to the next page.                                                       | click next button move next page                   | submitter |\n",
            "| 15 | 4b.2a.2           | viewNextResult | The system shows the next result.                                                                                   | show next result                                   | system    |\n",
            "+----+-------------------+----------------+---------------------------------------------------------------------------------------------------------------------+----------------------------------------------------+-----------+\n",
            "Destructor called.\n",
            "\n",
            "ucd2\n",
            "+----+------------------+----------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------+-------------------+\n",
            "|    | id               | usecase              | flowOfEvents                                                                                                                   | aksi                                                                     | aktor             |\n",
            "|----+------------------+----------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------+-------------------|\n",
            "|  0 | basic_flow       | nan                  | nan                                                                                                                            | empty                                                                    |                   |\n",
            "|  1 | 1                | searchResearcher     | The actor enters a keyword on the search field and clicks on the Search Button.                                                | enters keyword search field click search button                          | submitter; viewer |\n",
            "|  2 | 2                | searchResearcher     | The system shows a progress bar.                                                                                               | show progress bar                                                        | system            |\n",
            "|  3 | 3                | searchResearcher     | After it has finished searching; the system views the list of researchers which are relevant to the keyword being entered.     | view list researcher relevant keyword entered                            | system            |\n",
            "|  4 | alternativeFlow  | nan                  | nan                                                                                                                            | empty                                                                    |                   |\n",
            "|  5 | extension_points | nan                  | nan                                                                                                                            | empty                                                                    |                   |\n",
            "|  6 | 3a               | orderByRelevancy     | The actor can change the view of search result based on Order by Relevancy of the researchers to the given keyword.            | change view search result based order relevancy researcher given keyword | submitter; viewer |\n",
            "|  7 | 3a.1             | orderByRelevancy     | The actor clicks on Relevant menu                                                                                              | click relevant menu                                                      | submitter; viewer |\n",
            "|  8 | 3a.2             | orderByRelevancy     | The system refreshes the view and order the researchers based on their relevancy.                                              | refreshes view order researcher based relevancy                          | system            |\n",
            "|  9 | 3b               | orderByScore         | The actor can change the view of articles based on Order by Score of researchers.                                              | change view article based order score researcher                         | submitter; viewer |\n",
            "| 10 | 3b.1             | orderByScore         | The actor clicks on Score menu                                                                                                 | click score menu                                                         | submitter; viewer |\n",
            "| 11 | 3b.2             | orderByScore         | The system refreshes the view and order the researchers based on their scores.                                                 | refreshes view order researcher based score                              | system            |\n",
            "| 12 | 3c               | viewDetailResearcher | The actor can View Detail Researcher of profile.                                                                               | view detail researcher profile                                           | submitter; viewer |\n",
            "| 13 | 3c.1             | viewDetailResearcher | The Submitter clicks on the name of the researcher.                                                                            | click name researcher                                                    | submitter         |\n",
            "| 14 | 3c.2             | viewDetailResearcher | The system shows the profile and list of his/ her published articles.                                                          | show profile list published article                                      | system            |\n",
            "| 15 | 3d.2a            | removeArticle        | The Submitter remove his Article.                                                                                              | remove article                                                           | submitter         |\n",
            "| 16 | 3d.2a.1          | removeArticle        | The Submitter clicks on Remove button of the article.                                                                          | click remove button article                                              | submitter         |\n",
            "| 17 | 3d.2a.2          | removeArticle        | The system reshows the profile and list of his/ her published articles.                                                        | reshows profile list published article                                   | system            |\n",
            "| 18 | 3d.2b            | editProfile          | The Submitter Edit his/ her Profile.                                                                                           | edit profile                                                             | submitter         |\n",
            "| 19 | 3d.2b.1          | editProfile          | The Submitter clicks on Edit Profile button.                                                                                   | click edit profile button                                                | submitter         |\n",
            "| 20 | 3d.2b.2          | editProfile          | The system shows the profile form.                                                                                             | show profile form                                                        | system            |\n",
            "| 21 | 3d.2b.2          | editProfile          | The Submitter edit a field; and click Save button.                                                                             | edit field                                                               | submitter         |\n",
            "| 22 | 3d.2b.2          | editProfile          | The system shows a progress bar. After it is finished; the system reshows the profile and list of his/ her published articles. | show progress bar                                                        | system            |\n",
            "+----+------------------+----------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------+-------------------+\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXOTKqbSnlnT",
        "outputId": "59da5049-5741-435e-a571-f84d5bcd7924"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import xlsxwriter\r\n",
        "import pandas as pd\r\n",
        "dfs  = {\r\n",
        "          'tabel_freqs' : freqs, \r\n",
        "          'tabel_ucd1' : ucd1,\r\n",
        "          'tabel_ucd2' : ucd2,\r\n",
        "        } \r\n",
        "\r\n",
        "writer = pd.ExcelWriter('/data/data_aksi_aktor.xlsx')\r\n",
        "\r\n",
        "for name,dataframe in dfs.items():\r\n",
        "    dataframe.to_excel(writer,name,index=False)\r\n",
        "\r\n",
        "writer.save()"
      ],
      "outputs": [],
      "metadata": {
        "id": "jC7M0Qd26sf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modul3: pencarian relasi"
      ],
      "metadata": {
        "id": "RkW-XQc8nYfJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "from pywsd import disambiguate\r\n",
        "from pywsd.similarity import max_similarity as maxsim\r\n",
        "from pywsd.cosine import cosine_similarity\r\n",
        "\r\n",
        "# template class ucdReq\r\n",
        "class ucdReq:\r\n",
        "\r\n",
        "  #inicsialisasi\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "\r\n",
        "  def useCaseWSDStopwords(self, keyword, id_keyword):\r\n",
        "    word_stopwords = [disambiguate(x) for x in self.keyword]\r\n",
        "    b = [len(word_tokenize(num)) for num in self.keyword]\r\n",
        "    c = max(b)\r\n",
        "    list_kolom = [\"data{}\".format(x) for x in range(0,c)]\r\n",
        "    word_synset_stopwords = [[n[1] for n in y] for y in word_stopwords]\r\n",
        "    hasilUcd_stopwords = pd.DataFrame(word_synset_stopwords, index= self.id_keyword, columns= list_kolom)\r\n",
        "    return hasilUcd_stopwords\r\n",
        "\r\n",
        "  #PengukuranUCD\r\n",
        "  def useCaseMeasurement(self, keyword1, keyword2, id1, id2):\r\n",
        "    hasil_wsd = []\r\n",
        "    for num in keyword1:\r\n",
        "      text = [cosine_similarity(num, angka) for angka in keyword2]\r\n",
        "      hasil_wsd.append(text)\r\n",
        "    df = pd.DataFrame(hasil_wsd, index= id1, columns= id2)\r\n",
        "    return df\r\n",
        "\r\n",
        "  def change_case(self, word):\r\n",
        "      return ''.join([' '+i.lower() if i.isupper()\r\n",
        "          else i for i in word]).lstrip(' ')\r\n",
        "\r\n",
        "  def __del__(self):\r\n",
        "    print ('Destructor called.')\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  try:\r\n",
        "      MyucdReq = ucdReq()\r\n",
        "      ucd1= ucd1.dropna()\r\n",
        "      tbl_1 = MyucdReq.useCaseMeasurement(keyword1= freqs.aksi, keyword2=ucd1.aksi , id1= freqs.id, id2= ucd1.usecase)\r\n",
        "      tbl_1.rename(columns = {'insertMetadata':'UC01', 'searchArticle':'UC03', 'viewNextResult':'UC04'}, inplace = True)\r\n",
        "      print(\"\\nData Pengukuran antara functional dan ucd1 (txt)\")\r\n",
        "      print(tabulate(tbl_1, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      ucd2= ucd2.dropna()\r\n",
        "      tbl_2 = MyucdReq.useCaseMeasurement(keyword1= freqs.aksi, keyword2=ucd2.aksi , id1= freqs.id, id2= ucd2.usecase)\r\n",
        "      tbl_2.rename(columns = {'searchResearcher':'UC02', 'orderByRelevancy':'UC05', 'orderByScore':'UC06', \r\n",
        "                              'viewDetailResearcher':'UC07', 'removeArticle':'UC09', 'editProfile':'UC08' }, inplace = True)\r\n",
        "      print(\"\\nData Pengukuran antara functional dan ucd2 (txt)\")\r\n",
        "      print(tabulate(tbl_2, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      tbl_3 = pd.concat([tbl_1, tbl_2], axis= 1)\r\n",
        "      tbl_3['uc01'] = tbl_3.UC01.values.max(1)\r\n",
        "      tbl_3['uc02'] = tbl_3.UC02.values.max(1)\r\n",
        "      tbl_3['uc03'] = tbl_3.UC03.values.max(1)\r\n",
        "      tbl_3['uc04'] = tbl_3.UC04.values.max(1)\r\n",
        "      tbl_3['uc05'] = tbl_3.UC05.values.max(1)\r\n",
        "      tbl_3['uc06'] = tbl_3.UC06.values.max(1)\r\n",
        "      tbl_3['uc07'] = tbl_3.UC07.values.max(1)\r\n",
        "      tbl_3['uc08'] = tbl_3.UC08.values.max(1)\r\n",
        "      tbl_3['uc09'] = tbl_3.UC09.values.max(1)\r\n",
        "      tbl_3filter = tbl_3.drop(['UC01','UC02', 'UC03', 'UC04', 'UC05', 'UC06', 'UC07', 'UC08', 'UC09'], axis= 1)\r\n",
        "      print(\"\\nData filter pengukuran maksmimum (txt)\")\r\n",
        "      print(tabulate(tbl_3filter, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      threshold = 0.6\r\n",
        "      d = tbl_3filter.values >= threshold\r\n",
        "      d1 = pd.DataFrame(d, index= tbl_3filter.index, columns= tbl_3filter.columns)\r\n",
        "      mask = d1.isin([True])\r\n",
        "      d2 = d1.where(mask, other= 0)\r\n",
        "      mask2 = d1.isin([False])\r\n",
        "      tbl_4 = d2.where(mask2, other= 1)\r\n",
        "      print(\"\\nData hasil relasi antara kebutuhan dan kasus penggunaan (txt)\")\r\n",
        "      print(tabulate(tbl_4, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      # Driver code\r\n",
        "      data_ucd = []\r\n",
        "      for num in useCaseTable.name:\r\n",
        "        data_ucd.append(MyucdReq.change_case(num))\r\n",
        "      tbl_1x = MyucdReq.useCaseMeasurement(keyword1= freqs.aksi, keyword2=data_ucd , id1= freqs.id, id2= useCaseTable.name)\r\n",
        "      tbl_1x.rename(columns = {'insertMetadata':'uc01', 'searchArticle':'uc03', 'viewNextResult':'uc04', \r\n",
        "                               'searchResearcher':'uc02', 'orderByRelevancy':'uc05', 'orderByScore':'uc06', \r\n",
        "                              'viewDetailOfResearcher':'uc07', 'removeArticle':'uc09', 'editProfile':'uc08' }, inplace = True)\r\n",
        "      print(\"\\nData hasil relasi antara kebutuhan dan kasus penggunaan (xmi)\")\r\n",
        "      print(tabulate(tbl_1x, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      threshold = 0.6\r\n",
        "      dt = tbl_1x.values >= threshold\r\n",
        "      dt1 = pd.DataFrame(dt, index= tbl_1x.index, columns= tbl_1x.columns)\r\n",
        "      mask = dt1.isin([True])\r\n",
        "      dt2 = dt1.where(mask, other= 0)\r\n",
        "      mask2 = dt2.isin([False])\r\n",
        "      tbl_5 = dt2.where(mask2, other= 1)\r\n",
        "      print(\"\\nData hasil relasi antara kebutuhan dan kasus penggunaan (xmi)\")\r\n",
        "      print(tabulate(tbl_5, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      list_usecase = ['uc01', 'uc02', 'uc03', 'uc04', 'uc05', 'uc06', 'uc07', 'uc08', 'uc09']\r\n",
        "      tbl_6 = tbl_4.merge(tbl_5, how= 'inner', left_index= True, right_index= True, on= list_usecase)\r\n",
        "      print(\"\\nData hasil join relasi antara kebutuhan dan kasus penggunaan (txt dan xmi)\")\r\n",
        "      print(tabulate(tbl_6, headers = 'keys', tablefmt = 'psql'))\r\n",
        "\r\n",
        "      MyucdReq.__del__()\r\n",
        "\r\n",
        "  except OSError as err:\r\n",
        "      print(\"OS error: {0}\".format(err))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Destructor called.\n",
            "\n",
            "Data Pengukuran antara functional dan ucd1 (txt)\n",
            "+------+---------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+--------+----------+\n",
            "| id   |    UC01 |     UC01 |     UC01 |     UC01 |   UC01 |     UC03 |     UC03 |     UC03 |     UC03 |     UC03 |     UC04 |   UC04 |     UC04 |\n",
            "|------+---------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+--------+----------|\n",
            "| F01  | 0.57735 | 0.288675 | 0.654654 | 0        |      0 | 0.436436 | 0.235702 | 0        | 0.258199 | 0.57735  | 0        |      0 | 0        |\n",
            "| F02  | 0       | 0        | 0        | 0        |      0 | 0.338062 | 0.365148 | 0        | 0.2      | 0.223607 | 0        |      0 | 0        |\n",
            "| F03  | 0       | 0        | 0        | 0        |      0 | 0        | 0        | 0        | 0        | 0        | 0        |      0 | 0        |\n",
            "| F04  | 0       | 0        | 0.169031 | 0        |      0 | 0.169031 | 0.182574 | 0        | 0.2      | 0.223607 | 0        |      0 | 0        |\n",
            "| F05  | 0       | 0        | 0        | 0        |      0 | 0        | 0        | 0        | 0        | 0        | 0.258199 |      0 | 0        |\n",
            "| F06  | 0       | 0        | 0.218218 | 0        |      0 | 0.218218 | 0.235702 | 0        | 0.258199 | 0.288675 | 0        |      0 | 0        |\n",
            "| F07  | 0       | 0        | 0        | 0        |      0 | 0        | 0        | 0        | 0        | 0        | 0        |      0 | 0        |\n",
            "| F08  | 0       | 0.288675 | 0        | 0.666667 |      0 | 0        | 0        | 0.666667 | 0        | 0.288675 | 0        |      0 | 0.333333 |\n",
            "+------+---------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+--------+----------+\n",
            "\n",
            "Data Pengukuran antara functional dan ucd2 (txt)\n",
            "+------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+\n",
            "| id   |     UC02 |   UC02 |     UC02 |     UC05 |     UC05 |     UC05 |     UC06 |     UC06 |     UC06 |     UC07 |     UC07 |     UC07 |     UC09 |     UC09 |     UC09 |     UC08 |     UC08 |     UC08 |   UC08 |   UC08 |\n",
            "|------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------|\n",
            "| F01  | 0        |      0 | 0        | 0        | 0        | 0        | 0.218218 | 0        | 0        | 0        | 0        | 0.258199 | 0.408248 | 0.288675 | 0.258199 | 0        | 0        | 0        |    0   |      0 |\n",
            "| F02  | 0.447214 |      0 | 0.547723 | 0.424264 | 0.258199 | 0.182574 | 0.169031 | 0        | 0.182574 | 0.223607 | 0.258199 | 0        | 0        | 0        | 0        | 0        | 0        | 0        |    0   |      0 |\n",
            "| F03  | 0        |      0 | 0.166667 | 0.129099 | 0        | 0.166667 | 0.308607 | 0.235702 | 0.333333 | 0.204124 | 0.235702 | 0        | 0        | 0        | 0        | 0        | 0        | 0        |    0   |      0 |\n",
            "| F04  | 0        |      0 | 0        | 0.141421 | 0        | 0.182574 | 0.169031 | 0        | 0        | 0        | 0        | 0.2      | 0.316228 | 0.223607 | 0.2      | 0        | 0        | 0        |    0   |      0 |\n",
            "| F05  | 0        |      0 | 0.365148 | 0.282843 | 0        | 0.365148 | 0.338062 | 0        | 0.365148 | 0.894427 | 0.258199 | 0.2      | 0        | 0        | 0.2      | 0.316228 | 0.223607 | 0.258199 |    0   |      0 |\n",
            "| F06  | 0        |      0 | 0        | 0        | 0        | 0        | 0.218218 | 0        | 0        | 0.288675 | 0        | 0.516398 | 0.816497 | 0.57735  | 0.516398 | 0.408248 | 0.288675 | 0.333333 |    0   |      0 |\n",
            "| F07  | 0        |      0 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.353553 | 0        | 0.316228 | 0        | 0        | 0.316228 | 1        | 0.707107 | 0.408248 |    0.5 |      0 |\n",
            "| F08  | 0        |      1 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.258199 | 0        | 0        | 0        | 0        | 0        | 0.333333 |    0   |      1 |\n",
            "+------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+\n",
            "\n",
            "Data filter pengukuran maksmimum (txt)\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| id   |     uc01 |     uc02 |     uc03 |     uc04 |     uc05 |     uc06 |     uc07 |     uc08 |     uc09 |\n",
            "|------+----------+----------+----------+----------+----------+----------+----------+----------+----------|\n",
            "| F01  | 0.654654 | 0        | 0.57735  | 0        | 0        | 0.218218 | 0.258199 | 0        | 0.408248 |\n",
            "| F02  | 0        | 0.547723 | 0.365148 | 0        | 0.424264 | 0.182574 | 0.258199 | 0        | 0        |\n",
            "| F03  | 0        | 0.166667 | 0        | 0        | 0.166667 | 0.333333 | 0.235702 | 0        | 0        |\n",
            "| F04  | 0.169031 | 0        | 0.223607 | 0        | 0.182574 | 0.169031 | 0.2      | 0        | 0.316228 |\n",
            "| F05  | 0        | 0.365148 | 0        | 0.258199 | 0.365148 | 0.365148 | 0.894427 | 0.316228 | 0.2      |\n",
            "| F06  | 0.218218 | 0        | 0.288675 | 0        | 0        | 0.218218 | 0.516398 | 0.408248 | 0.816497 |\n",
            "| F07  | 0        | 0        | 0        | 0        | 0        | 0        | 0.353553 | 1        | 0.316228 |\n",
            "| F08  | 0.666667 | 1        | 0.666667 | 0.333333 | 0        | 0        | 0.258199 | 1        | 0        |\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "\n",
            "Data hasil relasi antara kebutuhan dan kasus penggunaan (txt)\n",
            "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
            "| id   |   uc01 |   uc02 |   uc03 |   uc04 |   uc05 |   uc06 |   uc07 |   uc08 |   uc09 |\n",
            "|------+--------+--------+--------+--------+--------+--------+--------+--------+--------|\n",
            "| F01  |      1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F02  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F03  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F04  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F05  |      0 |      0 |      0 |      0 |      0 |      0 |      1 |      0 |      0 |\n",
            "| F06  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      1 |\n",
            "| F07  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      1 |      0 |\n",
            "| F08  |      1 |      1 |      1 |      0 |      0 |      0 |      0 |      1 |      0 |\n",
            "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
            "\n",
            "Data hasil relasi antara kebutuhan dan kasus penggunaan (xmi)\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "| id   |     uc01 |     uc02 |     uc03 |     uc04 |     uc05 |     uc06 |     uc07 |     uc08 |     uc09 |\n",
            "|------+----------+----------+----------+----------+----------+----------+----------+----------+----------|\n",
            "| F01  | 0.816497 | 0        | 0.408248 | 0        | 0        | 0        | 0        | 0        | 0.408248 |\n",
            "| F02  | 0        | 0.632456 | 0.316228 | 0        | 0        | 0        | 0.223607 | 0        | 0        |\n",
            "| F03  | 0        | 0.288675 | 0        | 0        | 0        | 0.235702 | 0.204124 | 0        | 0        |\n",
            "| F04  | 0        | 0        | 0.316228 | 0        | 0.258199 | 0        | 0        | 0        | 0.316228 |\n",
            "| F05  | 0        | 0.316228 | 0        | 0.258199 | 0        | 0        | 0.67082  | 0.316228 | 0        |\n",
            "| F06  | 0        | 0        | 0.408248 | 0        | 0        | 0        | 0        | 0.408248 | 0.816497 |\n",
            "| F07  | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 1        | 0        |\n",
            "| F08  | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "\n",
            "Data hasil relasi antara kebutuhan dan kasus penggunaan (xmi)\n",
            "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
            "| id   |   uc01 |   uc02 |   uc03 |   uc04 |   uc05 |   uc06 |   uc07 |   uc08 |   uc09 |\n",
            "|------+--------+--------+--------+--------+--------+--------+--------+--------+--------|\n",
            "| F01  |      1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F02  |      0 |      1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F03  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F04  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F05  |      0 |      0 |      0 |      0 |      0 |      0 |      1 |      0 |      0 |\n",
            "| F06  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      1 |\n",
            "| F07  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      1 |      0 |\n",
            "| F08  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
            "\n",
            "Data hasil join relasi antara kebutuhan dan kasus penggunaan (txt dan xmi)\n",
            "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
            "| id   |   uc01 |   uc02 |   uc03 |   uc04 |   uc05 |   uc06 |   uc07 |   uc08 |   uc09 |\n",
            "|------+--------+--------+--------+--------+--------+--------+--------+--------+--------|\n",
            "| F01  |      1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F02  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F03  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F04  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |\n",
            "| F05  |      0 |      0 |      0 |      0 |      0 |      0 |      1 |      0 |      0 |\n",
            "| F06  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      1 |\n",
            "| F07  |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      1 |      0 |\n",
            "| F08  |      1 |      1 |      1 |      0 |      0 |      0 |      0 |      1 |      0 |\n",
            "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
            "Destructor called.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETzqGKt_nXVU",
        "outputId": "0cf45257-4d6f-493e-d67d-2e45ba1278fe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import xlsxwriter\n",
        "import pandas as pd\n",
        "dfs  = {\n",
        "          'tabel_freqs_ucd1'    : tbl_1, \n",
        "          'tabel_freqs_ucd2'    : tbl_2,\n",
        "          'tabel_filter'        : tbl_3filter,\n",
        "          'tabel_relasi_txt'    : tbl_4,\n",
        "          'tabel_relasi_xmi'    : tbl_5,\n",
        "          'tabel_join_txt_xmi'  : tbl_6,\n",
        "        } \n",
        "\n",
        "writer = pd.ExcelWriter('/content/mydrive/MyDrive/dataset/data_relasi.xlsx')\n",
        "\n",
        "for name,dataframe in dfs.items():\n",
        "    dataframe.to_excel(writer,name,index=False)\n",
        "\n",
        "writer.save()"
      ],
      "outputs": [],
      "metadata": {
        "id": "S3XyBiqc8UnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluasi"
      ],
      "metadata": {
        "id": "QcODID7GGsG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "threshold = 0.1\r\n",
        "d = df_filter.values >= threshold\r\n",
        "d1 = pd.DataFrame(d, index= df_filter.index, columns= df_filter.columns)\r\n",
        "mask = d1.isin([True])\r\n",
        "d2 = d1.where(mask, other= 0)\r\n",
        "mask2 = d1.isin([False])\r\n",
        "tbl_4 = d2.where(mask2, other= 1)\r\n",
        "tbl_4.values"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
              "       [0, 1, 1, 0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 1, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 1, 1, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 0, 1, 0, 0, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 0, 0, 1, 1, 0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYFzOjD-8Xgy",
        "outputId": "5f3bffbe-21bb-42f3-b321-95f10ecb98fe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def fulldataset(data, inputSRS):\r\n",
        "    xl = pd.ExcelFile(data)\r\n",
        "    dfs = {sh:xl.parse(sh) for sh in xl.sheet_names}\r\n",
        "    kalimat = dfs[inputSRS]\r\n",
        "    kalimat_semua = kalimat.head(len(kalimat))\r\n",
        "    return kalimat_semua\r\n",
        "\r\n",
        "file3 = r'/content/mydrive/MyDrive/dataset/data_relasi.xlsx'\r\n",
        "dataGT = 'ground_truth'\r\n",
        "tbl_grd = fulldataset(data= file3, inputSRS= dataGT)\r\n",
        "tbl_grd = tbl_grd.drop(['index'], axis= 1)\r\n",
        "tbl_grd.index= d3.index\r\n",
        "tbl_grd.values"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1OyJmar_eB1",
        "outputId": "397eec68-b021-4c89-9db6-3ab804f7b8e9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tbl_4_list = tbl_4.values.astype(int)\n",
        "tbl_grd_list = tbl_grd.values.astype(int)\n",
        "y_actual = tbl_4_list\n",
        "y_predicted = tbl_grd_list\n",
        "print(\"akurasi\", metrics.accuracy_score(y_true= y_actual, y_pred= y_predicted))\n",
        "print(\"presion\", metrics.precision_score(y_true= y_actual, y_pred= y_predicted, average= 'macro'))\n",
        "print(\"recall\", metrics.recall_score(y_true= y_actual, y_pred= y_predicted, average= 'macro'))\n",
        "print(\"metrics {}\".format(metrics.classification_report(y_true= y_actual, y_pred= y_predicted)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "akurasi 0.0\n",
            "presion 0.8888888888888888\n",
            "recall 0.24351851851851855\n",
            "metrics               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         4\n",
            "           1       1.00      0.50      0.67         4\n",
            "           2       1.00      0.20      0.33         5\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      0.25      0.40         4\n",
            "           5       1.00      0.17      0.29         6\n",
            "           6       1.00      0.12      0.22         8\n",
            "           7       1.00      0.25      0.40         4\n",
            "           8       1.00      0.20      0.33         5\n",
            "\n",
            "   micro avg       1.00      0.24      0.38        42\n",
            "   macro avg       0.89      0.24      0.37        42\n",
            "weighted avg       0.95      0.24      0.37        42\n",
            " samples avg       1.00      0.25      0.39        42\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioZB3zawCN3t",
        "outputId": "4ab5d547-c970-4c52-cb97-a954d9c54bba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "#define array of actual values\n",
        "y_actual = [\n",
        "1,0,1,0,0,0,0,0,1,\n",
        "0,1,1,0,1,0,0,0,0,\n",
        "0,0,0,0,0,1,0,0,0,\n",
        "0,0,0,0,0,0,0,0,1,\n",
        "0,1,0,0,1,1,1,1,0,\n",
        "0,0,0,0,0,0,1,1,1,\n",
        "0,0,0,0,0,0,1,1,1,\n",
        "1,1,1,1,0,0,0,1,0,\n",
        "]\n",
        "\n",
        "#define array of predicted values\n",
        "y_predicted = [\n",
        "1,0,0,0,0,0,0,0,0,\n",
        "0,1,1,0,0,0,0,0,0,\n",
        "0,0,0,0,0,1,0,0,0,\n",
        "0,0,0,0,1,0,0,0,0,\n",
        "0,0,0,0,0,0,1,0,0,\n",
        "0,0,0,0,0,0,0,0,1,\n",
        "0,0,0,0,0,0,0,1,0,\n",
        "1,1,0,0,0,0,0,0,0,\n",
        "]\n",
        "\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true= y_actual, y_pred= y_predicted).ravel()\n",
        "\n",
        "print(\"false positif : \",fp)\n",
        "print(\"false negative : \",fn)\n",
        "print(\"true positive : \", tp) \n",
        "print(\"true negative : \", tn)\n",
        "\n",
        "print(\"akurasi\", metrics.accuracy_score(y_true= y_actual, y_pred= y_predicted))\n",
        "print(\"recall\", metrics.recall_score(y_true= y_actual, y_pred= y_predicted))\n",
        "print(\"presion\", metrics.precision_score(y_true= y_actual, y_pred= y_predicted))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "false positif :  1\n",
            "false negative :  15\n",
            "true positive :  9\n",
            "true negative :  47\n",
            "akurasi 0.7777777777777778\n",
            "recall 0.375\n",
            "presion 0.9\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8IdWfjfGKsZ",
        "outputId": "d8fd2012-4e72-4a4b-8964-7cf4bd3435f8"
      }
    }
  ]
}