{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modul_partof_(ekspart).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0J8b1rzYYtU0",
        "oaihAadDQxbs",
        "PCoRXL8tybma",
        "jEubXuvy11cz",
        "UZ1wNq5VyIRw",
        "OQ9rg4RMSLzN"
      ],
      "authorship_tag": "ABX9TyPGjhxSoeDLYJFq/gIMPWG0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asyrofist/Extraction-Requirement/blob/main/modul_partof_(ekspart).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqclWxczkBRI",
        "outputId": "0da36dfe-e79b-4fbe-b020-46179eb3a0ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o38G-s9c_sw8"
      },
      "source": [
        "!pip install -U pywsd\n",
        "!pip install -U wn==0.0.23\n",
        "!pip install XlsxWriter\n",
        "!pip install stanfordcorenlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J8b1rzYYtU0"
      },
      "source": [
        "#modul 1: parsing kebutuhan partOf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RktFgAG1Yz-j",
        "outputId": "e5b1b769-c3cc-445a-d4cc-2a9bcbc2d71c"
      },
      "source": [
        "# function\n",
        "import nltk\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from stanfordcorenlp import StanfordCoreNLP\n",
        "from nltk.parse.corenlp import CoreNLPParser\n",
        "from nltk.tag.stanford import CoreNLPPOSTagger\n",
        "from nltk.tag.stanford import CoreNLPNERTagger\n",
        "\n",
        "class partOf: #template\n",
        "\n",
        "  def __init__(self, inputData  = r'/content/drive/MyDrive/dataset/dataset_2.xlsx', \n",
        "               dataStanford     = r'/content/drive/MyDrive/stanford-corenlp-4.0.0',\n",
        "               urlStanford      = 'http://corenlp.run/'):\n",
        "    self.data         = inputData\n",
        "    self.dataTag      = dataStanford\n",
        "    self.stanford_url = urlStanford\n",
        "\n",
        "  def fulldataset(self, inputSRS):\n",
        "    xl = pd.ExcelFile(self.data)\n",
        "    dfs = {sh:xl.parse(sh) for sh in xl.sheet_names}\n",
        "    kalimat = dfs[inputSRS]\n",
        "    kalimat_semua = kalimat.head(len(kalimat))\n",
        "    return kalimat_semua\n",
        "\n",
        "  def preprocessing(self):\n",
        "    xl = pd.ExcelFile(self.data)\n",
        "    for sh in xl.sheet_names:\n",
        "      df = xl.parse(sh)\n",
        "      print('Processing: [{}] ...'.format(sh))\n",
        "      print(df.head())\n",
        "\n",
        "  # nltk stanford\n",
        "  def parsing(self, data):\n",
        "      parser = CoreNLPParser(url=self.stanford_url)\n",
        "      next(parser.raw_parse(data)).pretty_print()\n",
        "\n",
        "  def postag(self, data):\n",
        "      stpos = CoreNLPPOSTagger(url=self.stanford_url)\n",
        "      print(stpos.tag(data.split()))\n",
        "\n",
        "  def nertag(self, data):\n",
        "      stner = CoreNLPNERTagger(url=self.stanford_url)\n",
        "      print(stner.tag(data.split()))\n",
        "      \n",
        "  # stanford library\n",
        "  def stanfordPostag(self, sentence):\n",
        "      nlp = StanfordCoreNLP(self.dataTag)\n",
        "      postag =  (nlp.pos_tag(sentence))\n",
        "      nlp.close() # Do not forget to close! The backend server will consume a lot memery.\n",
        "      return postag\n",
        "      \n",
        "  def stanfordNamedentities(self, sentence):\n",
        "      nlp = StanfordCoreNLP(self.dataTag)\n",
        "      print (nlp.ner(sentence))\n",
        "      nlp.close() # Do not forget to close! The backend server will consume a lot memery.\n",
        "      \n",
        "  def stanfordConstituencyparsing(self, sentence):\n",
        "      nlp = StanfordCoreNLP(self.dataTag)\n",
        "      print (nlp.parse(sentence))\n",
        "      nlp.close() # Do not forget to close! The backend server will consume a lot memery.\n",
        "      \n",
        "  def stanfordDependencyparsing(self, sentence):\n",
        "      nlp = StanfordCoreNLP(self.dataTag)\n",
        "      print (nlp.dependency_parse(sentence))    \n",
        "      nlp.close() # Do not forget to close! The backend server will consume a lot memery.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "    myPartOf = partOf()    # myPartOf.preprocessing()\n",
        "    hasil_srs = []\n",
        "    dataSRS = '2005 - Grid 3D'\n",
        "    a = myPartOf.fulldataset(dataSRS)\n",
        "    for idx, num in zip(a['ID'], a['Requirement Statement']):\n",
        "        data = [x8 for x in num.split(\"(i.e., black on white background)\") \n",
        "                    for x1 in x.split(\":\\n\") for x2 in x1.split(\"(\") \n",
        "                    for x3 in x2.split(\".)\") for x4 in x3.split(\")\") \n",
        "                    for x5 in x4.split(\".\")for x6 in x5.split(\", so\")  \n",
        "                    for x7 in x6.split(\",\") for x8 in x7.split(\"and\") ]\n",
        "        hasil_srs.append([idx, data])\n",
        "    a_df = pd.DataFrame(hasil_srs, columns = ['ID', 'Data'])\n",
        "    print(\"data {}\".format(dataSRS))\n",
        "    print(tabulate(a_df, headers = 'keys', tablefmt = 'psql'))\n",
        "\n",
        "    # detailing\n",
        "    idx = 7\n",
        "    idy = 1\n",
        "    hasil_split = hasil_srs[idx][idy]\n",
        "    x = hasil_split[3].replace(\"move\", \"\")\n",
        "    hasil_splita = hasil_split[1] + x\n",
        "    hasil_splitb = hasil_split[2] + x\n",
        "    hasil_splitc = hasil_split[3]\n",
        "    myTuple = [hasil_split[0], hasil_splita, hasil_splitb, hasil_splitc]\n",
        "    hasil_join = \",\".join(myTuple)\n",
        "\n",
        "    print(\"data dari {}\".format(hasil_srs[idx][0]))\n",
        "    for xi in hasil_join.split(\",\"): \n",
        "      print(\"\\n{}\".format(xi))\n",
        "      myPartOf.stanfordConstituencyparsing(xi) #drive parsing\n",
        "      # myPartOf.parsing(xi) #online parsing\n",
        "\n",
        "  except OSError as err:\n",
        "    print(\"OS error: {0}\".format(err))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data 2005 - Grid 3D\n",
            "+----+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|    | ID   | Data                                                                                                                                                                                                                                                                                               |\n",
            "|----+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "|  0 | F01  | ['The product shall plot the data points in a scientifically correct manner']                                                                                                                                                                                                                      |\n",
            "|  1 | F02  | ['The grid axis should be labelled correctly according to the input from the data file']                                                                                                                                                                                                           |\n",
            "|  2 | F03  | ['Data points should be coloured in accordance to the cluster number ', 'contained in the data file', '']                                                                                                                                                                                          |\n",
            "|  3 | F04  | ['The product should be able to h', 'le up to 2000 data points']                                                                                                                                                                                                                                   |\n",
            "|  4 | F05  | ['A single click of the mouse over a data point should bring up the name of the data point', '']                                                                                                                                                                                                   |\n",
            "|  5 | F06  | [\"A double-click of the mouse over the data point should cause the application to display all the data point's details\", '']                                                                                                                                                                       |\n",
            "|  6 | F07  | ['The product should allow multiple points to clicked so that multiple names can be displayed']                                                                                                                                                                                                    |\n",
            "|  7 | F08  | ['The product should allow the grid to be oriented by the user', ' Rotation', ' zoom ', ' move functions should be employed', '']                                                                                                                                                                  |\n",
            "|  8 | F09  | ['The data file should contain', '', 'A name for the data point', ' 3 parameters from which the data point is to be plotted', ' A single parameter to designate the colour of the point', ' This is the attribute that is to be used\\nas the comparison', ' A description for the data point', ''] |\n",
            "|  9 | NF01 | ['The points should be large enough to see ', ' select']                                                                                                                                                                                                                                           |\n",
            "| 10 | NF02 | ['The points should not be too big', ' as to distort the overall pattern of the point spread']                                                                                                                                                                                                     |\n",
            "| 11 | NF03 | ['The axis should be clearly labelled ', ' easily recognised after the grid has been oriented into a different position', '']                                                                                                                                                                      |\n",
            "| 12 | NF04 | ['The application should be coloured so that the screen shots can be printed out clearly ', '', '']                                                                                                                                                                                                |\n",
            "| 13 | NF05 | ['The application should be intuitive ', ' not require any specialist training']                                                                                                                                                                                                                   |\n",
            "| 14 | NF06 | ['The program should start within 30 seconds', ' This depends on the number of data points that are to be plotted', '']                                                                                                                                                                            |\n",
            "| 15 | NF07 | ['The interaction with the data points should have a delay of no longer than 2 seconds']                                                                                                                                                                                                           |\n",
            "| 16 | NF08 | [\"The response to a change in the orientation should be fast enough to avoid interrupting the user's flow of thought\", '']                                                                                                                                                                         |\n",
            "+----+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "data dari F08\n",
            "\n",
            "The product should allow the grid to be oriented by the user\n",
            "(ROOT\n",
            "  (S\n",
            "    (NP (DT The) (NN product))\n",
            "    (VP (MD should)\n",
            "      (VP (VB allow)\n",
            "        (NP (DT the) (NN grid))\n",
            "        (S\n",
            "          (VP (TO to)\n",
            "            (VP (VB be)\n",
            "              (ADJP (VBN oriented)\n",
            "                (PP (IN by)\n",
            "                  (NP (DT the) (NN user)))))))))))\n",
            "\n",
            " Rotation  functions should be employed\n",
            "(ROOT\n",
            "  (S\n",
            "    (NP (NN Rotation) (NNS functions))\n",
            "    (VP (MD should)\n",
            "      (VP (VB be)\n",
            "        (VP (VBN employed))))))\n",
            "\n",
            " zoom   functions should be employed\n",
            "(ROOT\n",
            "  (S\n",
            "    (VP (VB zoom)\n",
            "      (S\n",
            "        (NP (NNS functions))\n",
            "        (VP (MD should)\n",
            "          (VP (VB be)\n",
            "            (VP (VBN employed))))))))\n",
            "\n",
            " move functions should be employed\n",
            "(ROOT\n",
            "  (S\n",
            "    (VP (VB move)\n",
            "      (S\n",
            "        (NP (NNS functions))\n",
            "        (VP (MD should)\n",
            "          (VP (VB be)\n",
            "            (VP (VBN employed))))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaihAadDQxbs"
      },
      "source": [
        "# modul2: pencarian relasi partOf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsLmKUBtyNya"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZkYnKBCjfKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b657b2b-ed8e-43b4-b434-c9a0d011a361"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from spacy.lang.en import English\n",
        "from pywsd.cosine import cosine_similarity\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class wsd_partof:\n",
        "  def __init__(self):\n",
        "      pass\n",
        "\n",
        "  def fulldataset(self, dataFile, inputSRS):\n",
        "      xl = pd.ExcelFile(dataFile)\n",
        "      dfs = {sh:xl.parse(sh) for sh in xl.sheet_names}\n",
        "      kalimat = dfs[inputSRS]\n",
        "      kalimat_semua = kalimat.head(len(kalimat))\n",
        "      return kalimat_semua\n",
        "\n",
        "  def preprocessing(self, dataFile):\n",
        "    xl = pd.ExcelFile(dataFile)\n",
        "    for sh in xl.sheet_names:\n",
        "      df = xl.parse(sh)\n",
        "      print('Processing: [{}] ...'.format(sh))\n",
        "      print(df.head())\n",
        "\n",
        "  # cleaning text\n",
        "  def apply_cleaning_function_to_list(self, X):\n",
        "      cleaned_X = []\n",
        "      for element in X:\n",
        "          cleaned_X.append(wsd_partof.clean_text(self, raw_text= element))\n",
        "      return cleaned_X\n",
        "\n",
        "  def clean_text(self, raw_text):\n",
        "      nlp = English()\n",
        "      tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
        "      tokens = tokenizer(raw_text)\n",
        "      lemma_list = [token.lemma_.lower() for token in tokens if token.is_stop is False and token.is_punct is False and token.is_alpha is True]\n",
        "      joined_words = ( \" \".join(lemma_list))\n",
        "      return joined_words    \n",
        "      \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "      myWsd_partof = wsd_partof()\n",
        "      # myWsd_partof.preprocessing(dataFile= r'/content/drive/MyDrive/dataset/dataset_2_split.xlsx')\n",
        "\n",
        "      file1 = r'/content/drive/MyDrive/dataset/dataset_2.xlsx'\n",
        "      dataSRS =  '2005 - Grid 3D'\n",
        "      a = myWsd_partof.fulldataset(dataFile= file1, inputSRS= dataSRS)\n",
        "      list_req1 = list(a['Requirement Statement'])\n",
        "      id_req1 = list(a['ID'])\n",
        "      cleaned1 = myWsd_partof.apply_cleaning_function_to_list(X= list_req1)\n",
        "\n",
        "      file2 = r'/content/drive/MyDrive/dataset/dataset_2_split.xlsx'\n",
        "      b = myWsd_partof.fulldataset(dataFile= file2, inputSRS= dataSRS)\n",
        "      list_req2 = list(b['Requirement Statement'])\n",
        "      id_req2 = list(b['ID'])\n",
        "      cleaned2 = myWsd_partof.apply_cleaning_function_to_list(X= list_req2)\n",
        "\n",
        "      hasil_wsd = []\n",
        "      for num in cleaned1:\n",
        "        text = [cosine_similarity(num, angka) for angka in cleaned2]\n",
        "        hasil_wsd.append(text)\n",
        "\n",
        "      data_raw = pd.DataFrame(hasil_wsd, index= id_req1, columns= id_req2)\n",
        "      print(\"Hasil pengukuran semantik antar kebutuhan atomik dan non atomik {}\".format(dataSRS))\n",
        "      print(tabulate(data_raw, headers = 'keys', tablefmt = 'psql'))   \n",
        "\n",
        "      # thresholding\n",
        "      threshold = 0.2\n",
        "      d = data_raw.values >= threshold\n",
        "      d1 = pd.DataFrame(d, index= id_req1, columns= id_req2)\n",
        "      mask = d1.isin([True])\n",
        "      d2 = d1.where(mask, other= 0)\n",
        "      mask2 = d1.isin([False])\n",
        "      d3 = d2.where(mask2, other= 1)\n",
        "      print(\"\\nHasil ukur semantik diatas threshold {}\".format(threshold))\n",
        "      print(tabulate(d3, headers = 'keys', tablefmt = 'psql'))   \n",
        "\n",
        "      file3 = r'/content/drive/MyDrive/dataset/wsd/wsd_groundtruth.xlsx'\n",
        "      dataGT = 'grid3d_eval'\n",
        "      b3 = myWsd_partof.fulldataset(dataFile= file3, inputSRS= dataGT)\n",
        "      b3 = b3.drop(['Index'], axis= 1)\n",
        "      b3.index= d3.index\n",
        "      print(\"\\nData Hasil Ground Truth {}\".format(dataGT))\n",
        "      print(tabulate(b3, headers = 'keys', tablefmt = 'psql'))  \n",
        "\n",
        "      y_actual = d3.values.astype(int)\n",
        "      y_predicted = b3.values.astype(int)\n",
        "      print(\"akurasi\", metrics.accuracy_score(y_true= y_actual, y_pred= y_predicted))\n",
        "      print(\"presion\", metrics.precision_score(y_true= y_actual, y_pred= y_predicted, average= 'macro'))\n",
        "      print(\"recall\", metrics.recall_score(y_true= y_actual, y_pred= y_predicted, average= 'macro'))\n",
        "      print(\"metrics {}\".format(metrics.classification_report(y_true= y_actual, y_pred= y_predicted)))       \n",
        "\n",
        "  except OSError as err:\n",
        "    print(\"OS error: {0}\".format(err))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil pengukuran semantik antar kebutuhan atomik dan non atomik 2005 - Grid 3D\n",
            "+------+----------+----------+-----------+----------+----------+-----------+-----------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|      |      F01 |      F02 |       F03 |      F04 |      F05 |       F06 |       F07 |     F08a |    F08b |    F08c |     F08d |     F09a |     F09b |     F09c |     F09d |     F09e |    NF01a |    NF01b |     NF02 |    NF03a |    NF03b |    NF03c |    NF04a |    NF04b |    NF05a |    NF05b |    NF06a |    NF06b |    NF06c |     NF07 |     NF08 |\n",
            "|------+----------+----------+-----------+----------+----------+-----------+-----------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|\n",
            "| F01  | 1        | 0.125    | 0.319801  | 0.474342 | 0.204124 | 0.182574  | 0.223607  | 0.158114 | 0       | 0       | 0        | 0.267261 | 0.235702 | 0.125    | 0        | 0.176777 | 0.25     | 0.204124 | 0.133631 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.353553 | 0        | 0.288675 | 0        |\n",
            "| F02  | 0.125    | 1        | 0.319801  | 0.158114 | 0.204124 | 0.182574  | 0         | 0.158114 | 0       | 0       | 0        | 0.400892 | 0.353553 | 0.25     | 0        | 0.176777 | 0        | 0        | 0        | 0.408248 | 0.204124 | 0.176777 | 0        | 0        | 0        | 0        | 0        | 0.176777 | 0        | 0.144338 | 0        |\n",
            "| F03  | 0.319801 | 0.319801 | 1         | 0.40452  | 0.348155 | 0.3114    | 0.0953463 | 0        | 0       | 0       | 0        | 0.569803 | 0.502519 | 0.319801 | 0        | 0.301511 | 0.213201 | 0.174078 | 0.113961 | 0        | 0        | 0        | 0.213201 | 0        | 0        | 0        | 0        | 0.603023 | 0        | 0.369274 | 0        |\n",
            "| F04  | 0.474342 | 0.158114 | 0.40452   | 1        | 0.258199 | 0.23094   | 0.282843  | 0.2      | 0       | 0       | 0        | 0.338062 | 0.298142 | 0.158114 | 0        | 0.223607 | 0.316228 | 0.258199 | 0.169031 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.447214 | 0        | 0.365148 | 0        |\n",
            "| F05  | 0.204124 | 0.204124 | 0.348155  | 0.258199 | 1        | 0.745356  | 0         | 0        | 0       | 0       | 0        | 0.654654 | 0.57735  | 0.51031  | 0        | 0.57735  | 0        | 0        | 0.218218 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.288675 | 0        | 0.235702 | 0        |\n",
            "| F06  | 0.182574 | 0.182574 | 0.3114    | 0.23094  | 0.745356 | 1         | 0         | 0        | 0       | 0       | 0        | 0.58554  | 0.516398 | 0.365148 | 0        | 0.516398 | 0        | 0        | 0.19518  | 0        | 0        | 0        | 0.182574 | 0        | 0.182574 | 0.129099 | 0        | 0.258199 | 0        | 0.210819 | 0        |\n",
            "| F07  | 0.223607 | 0        | 0.0953463 | 0.282843 | 0        | 0         | 1         | 0.282843 | 0       | 0       | 0        | 0        | 0        | 0        | 0        | 0        | 0.223607 | 0.182574 | 0.119523 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.158114 | 0        | 0.129099 | 0        |\n",
            "| F08  | 0.117851 | 0.117851 | 0         | 0.149071 | 0        | 0         | 0.210819  | 0.745356 | 0.57735 | 0.57735 | 0.471405 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.333333 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.111111 |\n",
            "| F09  | 0.215666 | 0.269582 | 0.41382   | 0.272798 | 0.748383 | 0.629999  | 0         | 0        | 0       | 0       | 0        | 0.806947 | 0.813326 | 0.754829 | 0.152499 | 0.762493 | 0        | 0        | 0.230556 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.304997 | 0.152499 | 0.249029 | 0        |\n",
            "| NF01 | 0.204124 | 0        | 0.174078  | 0.258199 | 0        | 0         | 0.182574  | 0        | 0       | 0       | 0        | 0        | 0        | 0        | 0        | 0        | 0.816497 | 1        | 0.218218 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.288675 | 0        | 0.235702 | 0        |\n",
            "| NF02 | 0.133631 | 0        | 0.113961  | 0.169031 | 0.218218 | 0.19518   | 0.119523  | 0        | 0       | 0       | 0        | 0.142857 | 0.125988 | 0.133631 | 0        | 0.188982 | 0.267261 | 0.218218 | 1        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.188982 | 0        | 0.154303 | 0        |\n",
            "| NF03 | 0        | 0.353553 | 0         | 0        | 0        | 0         | 0         | 0.298142 | 0       | 0       | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.57735  | 0.57735  | 0.666667 | 0        | 0.125988 | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
            "| NF04 | 0        | 0        | 0.100504  | 0        | 0        | 0.0860663 | 0         | 0        | 0       | 0       | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.19245  | 0        | 0        | 0.471405 | 0.881917 | 0.235702 | 0.166667 | 0        | 0        | 0        | 0        | 0        |\n",
            "| NF05 | 0        | 0        | 0         | 0        | 0        | 0.11547   | 0         | 0        | 0       | 0       | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.316228 | 0        | 0.632456 | 0.894427 | 0        | 0        | 0        | 0        | 0        |\n",
            "| NF06 | 0.25     | 0.125    | 0.426401  | 0.316228 | 0.204124 | 0.182574  | 0.111803  | 0        | 0       | 0       | 0        | 0.267261 | 0.353553 | 0.125    | 0        | 0.176777 | 0.25     | 0.204124 | 0.133631 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.612372 | 0.707107 | 0.353553 | 0.433013 | 0        |\n",
            "| NF07 | 0.288675 | 0.144338 | 0.369274  | 0.365148 | 0.235702 | 0.210819  | 0.129099  | 0        | 0       | 0       | 0        | 0.308607 | 0.272166 | 0.144338 | 0        | 0.204124 | 0.288675 | 0.235702 | 0.154303 | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0.235702 | 0.408248 | 0        | 1        | 0        |\n",
            "| NF08 | 0        | 0        | 0         | 0        | 0        | 0         | 0         | 0.149071 | 0       | 0       | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 1        |\n",
            "+------+----------+----------+-----------+----------+----------+-----------+-----------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "\n",
            "Hasil ukur semantik diatas threshold 0.2\n",
            "+------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+\n",
            "|      |   F01 |   F02 |   F03 |   F04 |   F05 |   F06 |   F07 |   F08a |   F08b |   F08c |   F08d |   F09a |   F09b |   F09c |   F09d |   F09e |   NF01a |   NF01b |   NF02 |   NF03a |   NF03b |   NF03c |   NF04a |   NF04b |   NF05a |   NF05b |   NF06a |   NF06b |   NF06c |   NF07 |   NF08 |\n",
            "|------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------|\n",
            "| F01  |     1 |     0 |     1 |     1 |     1 |     0 |     1 |      0 |      0 |      0 |      0 |      1 |      1 |      0 |      0 |      0 |       1 |       1 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| F02  |     0 |     1 |     1 |     0 |     1 |     0 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      1 |      0 |      0 |       0 |       0 |      0 |       1 |       1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F03  |     1 |     1 |     1 |     1 |     1 |     1 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      1 |      0 |      1 |       1 |       0 |      0 |       0 |       0 |       0 |       1 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| F04  |     1 |     0 |     1 |     1 |     1 |     1 |     1 |      0 |      0 |      0 |      0 |      1 |      1 |      0 |      0 |      1 |       1 |       1 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| F05  |     1 |     1 |     1 |     1 |     1 |     1 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      1 |      0 |      1 |       0 |       0 |      1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| F06  |     0 |     0 |     1 |     1 |     1 |     1 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      1 |      0 |      1 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| F07  |     1 |     0 |     0 |     1 |     0 |     0 |     1 |      1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       1 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F08  |     0 |     0 |     0 |     0 |     0 |     0 |     1 |      1 |      1 |      1 |      1 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F09  |     1 |     1 |     1 |     1 |     1 |     1 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      1 |      0 |      1 |       0 |       0 |      1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| NF01 |     1 |     0 |     0 |     1 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       1 |       1 |      1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       0 |      1 |      0 |\n",
            "| NF02 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       1 |       1 |      1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF03 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |      1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       1 |       1 |       1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF04 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       1 |       1 |       1 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF05 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       1 |       0 |       1 |       1 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF06 |     1 |     0 |     1 |     1 |     1 |     0 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      0 |      0 |      0 |       1 |       1 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       1 |       1 |      1 |      0 |\n",
            "| NF07 |     1 |     0 |     1 |     1 |     1 |     1 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      0 |      0 |      1 |       1 |       1 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       1 |       0 |      1 |      0 |\n",
            "| NF08 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      1 |\n",
            "+------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+\n",
            "\n",
            "Data Hasil Ground Truth grid3d_eval\n",
            "+------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+\n",
            "|      |   F01 |   F02 |   F03 |   F04 |   F05 |   F06 |   F07 |   F08a |   F08b |   F08c |   F08d |   F09a |   F09b |   F09c |   F09d |   F09e |   NF01a |   NF01b |   NF02 |   NF03a |   NF03b |   NF03c |   NF04a |   NF04b |   NF05a |   NF05b |   NF06a |   NF06b |   NF06c |   NF07 |   NF08 |\n",
            "|------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------|\n",
            "| F01  |     1 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F02  |     0 |     1 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F03  |     0 |     0 |     1 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F04  |     0 |     0 |     0 |     1 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F05  |     0 |     0 |     0 |     0 |     1 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F06  |     0 |     0 |     0 |     0 |     0 |     1 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F07  |     0 |     0 |     0 |     0 |     0 |     0 |     1 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F08  |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      1 |      1 |      1 |      1 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| F09  |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      1 |      1 |      1 |      1 |      1 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF01 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       1 |       1 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF02 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF03 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       1 |       1 |       1 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF04 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       1 |       1 |       0 |       0 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF05 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       1 |       1 |       0 |       0 |       0 |      0 |      0 |\n",
            "| NF06 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       1 |       1 |       1 |      0 |      0 |\n",
            "| NF07 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      1 |      0 |\n",
            "| NF08 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |      0 |       0 |       0 |      0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |       0 |      0 |      1 |\n",
            "+------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+\n",
            "akurasi 0.058823529411764705\n",
            "presion 0.967741935483871\n",
            "recall 0.4051075268817204\n",
            "metrics               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.11      0.20         9\n",
            "           1       1.00      0.20      0.33         5\n",
            "           2       1.00      0.11      0.20         9\n",
            "           3       1.00      0.10      0.18        10\n",
            "           4       1.00      0.10      0.18        10\n",
            "           5       1.00      0.17      0.29         6\n",
            "           6       1.00      0.25      0.40         4\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       1.00      1.00      1.00         1\n",
            "           9       1.00      1.00      1.00         1\n",
            "          10       1.00      1.00      1.00         1\n",
            "          11       1.00      0.11      0.20         9\n",
            "          12       1.00      0.11      0.20         9\n",
            "          13       1.00      0.20      0.33         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       1.00      0.17      0.29         6\n",
            "          16       1.00      0.12      0.22         8\n",
            "          17       1.00      0.17      0.29         6\n",
            "          18       1.00      0.25      0.40         4\n",
            "          19       1.00      0.50      0.67         2\n",
            "          20       1.00      0.50      0.67         2\n",
            "          21       1.00      0.50      0.67         2\n",
            "          22       1.00      0.33      0.50         3\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       1.00      0.50      0.67         2\n",
            "          25       1.00      1.00      1.00         1\n",
            "          26       1.00      0.50      0.67         2\n",
            "          27       1.00      0.11      0.20         9\n",
            "          28       1.00      1.00      1.00         1\n",
            "          29       1.00      0.11      0.20         9\n",
            "          30       1.00      1.00      1.00         1\n",
            "\n",
            "   micro avg       0.97      0.21      0.35       141\n",
            "   macro avg       0.97      0.41      0.50       141\n",
            "weighted avg       1.00      0.21      0.32       141\n",
            " samples avg       0.99      0.32      0.43       141\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJOVvDWSRLZ_"
      },
      "source": [
        "import xlsxwriter\n",
        "import pandas as pd\n",
        "dfs  = {\n",
        "          'tabel_dataset' : data_raw, \n",
        "          'tabel_threshold' : d3,\n",
        "          'tabel_groundtruth' : b3,\n",
        "        } \n",
        "\n",
        "writer = pd.ExcelWriter('/content/mydrive/MyDrive/dataset/wsd/data_wsd.xlsx')\n",
        "\n",
        "for name,dataframe in dfs.items():\n",
        "    dataframe.to_excel(writer,name,index=False)\n",
        "\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCoRXL8tybma"
      },
      "source": [
        "# Alternatif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEubXuvy11cz"
      },
      "source": [
        "### alternatif wsd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yggXqMi9jCvA",
        "outputId": "6a1a9d10-540c-4870-a226-187692e4aaec"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from pywsd import disambiguate\n",
        "from pywsd.similarity import similarity_by_path\n",
        "\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "lem = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "class ukur_partOf_alternatif:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fulldataset(self, data, inputSRS):\n",
        "    xl = pd.ExcelFile(data)\n",
        "    dfs = {sh:xl.parse(sh) for sh in xl.sheet_names}\n",
        "    kalimat = dfs[inputSRS]\n",
        "    kalimat_semua = kalimat.head(len(kalimat))\n",
        "    return kalimat_semua\n",
        "\n",
        "  def preprocessing(self, data):\n",
        "    xl = pd.ExcelFile(data)\n",
        "    for sh in xl.sheet_names:\n",
        "      df = xl.parse(sh)\n",
        "      print('Processing: [{}] ...'.format(sh))\n",
        "      print(df.head())\n",
        "\n",
        "  # cleaning text\n",
        "  def apply_cleaning_function_to_list(self, X):\n",
        "      cleaned_X = []\n",
        "      for element in X:\n",
        "          cleaned_X.append(ukur_partOf_alternatif.clean_text(self, raw_text= element))\n",
        "      return cleaned_X\n",
        "\n",
        "  def clean_text(self, raw_text):\n",
        "      text = raw_text.lower()\n",
        "      tokens = word_tokenize(text)\n",
        "      token_words = [w for w in tokens if w.isalpha()]\n",
        "      lemma_words = [lem.lemmatize(w) for w in token_words]\n",
        "      meaningful_words = [w for w in lemma_words if not w in stops]\n",
        "      joined_words = ( \" \".join(meaningful_words))\n",
        "      return joined_words    \n",
        "\n",
        "  def convert_tag(self, tag):\n",
        "      tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
        "      try:\n",
        "          return tag_dict[tag[0]]\n",
        "      except KeyError:\n",
        "          return None\n",
        "\n",
        "  def doc_to_synsets(self, doc):\n",
        "      tokens = nltk.word_tokenize(doc)\n",
        "      pos = nltk.pos_tag(tokens)\n",
        "      tags = [tag[1] for tag in pos]\n",
        "      wntag = [convert_tag(tag) for tag in tags]\n",
        "      ans = list(zip(tokens,wntag))\n",
        "      sets = [wn.synsets(x,y) for x,y in ans]\n",
        "      final = [val[0] for val in sets if len(val) > 0]\n",
        "      return final\n",
        "\n",
        "  def similarity_score(self, s1, s2):\n",
        "      s =[]\n",
        "      for i1 in s1:\n",
        "          r = []\n",
        "          scores = [x for x in [i1.path_similarity(i2) for i2 in s2] if x is not None]\n",
        "          if scores:\n",
        "              s.append(max(scores))\n",
        "      return sum(s)/len(s)\n",
        "\n",
        "  def document_path_similarity(self, doc1, doc2):\n",
        "      synsets1 = ukur_partOf_alternatif.doc_to_synsets(self, doc1)\n",
        "      synsets2 = ukur_partOf_alternatif.doc_to_synsets(self, doc2)\n",
        "      return (ukur_partOf_alternatif.similarity_score(self, synsets1, synsets2) + ukur_partOf_alternatif.similarity_score(self, synsets2, synsets1)) / 2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "      myUkur = ukur_partOf_alternatif()\n",
        "      file1 = r'/content/drive/MyDrive/dataset/dataset_2.xlsx'\n",
        "      file2 = r'/content/drive/MyDrive/dataset/dataset_2_split.xlsx'\n",
        "      dataSRS =  '2004 - colorcast'\n",
        "\n",
        "      a = myUkur.fulldataset(data= file1, inputSRS= dataSRS)\n",
        "      list_req1 = list(a['Requirement Statement'])\n",
        "      id_req1 = list(a['ID'])\n",
        "      cleaned1 = myUkur.apply_cleaning_function_to_list(X= list_req1)\n",
        "      synsets1 = [myUkur.doc_to_synsets(x) for x in cleaned1]\n",
        "\n",
        "      b = myUkur.fulldataset(data= file2, inputSRS= dataSRS)\n",
        "      list_req2 = list(b['Requirement Statement'])\n",
        "      id_req2 = list(b['ID'])\n",
        "      cleaned2 = myUkur.apply_cleaning_function_to_list(X= list_req2)\n",
        "      synsets2 = [myUkur.doc_to_synsets(x) for x in cleaned2]\n",
        "\n",
        "      data_list = []\n",
        "      for idx, num in enumerate(synsets1):\n",
        "        a = [myUkur.similarity_score(num, angka) for idy, angka in enumerate(synsets2)]\n",
        "        data_list.append(a)\n",
        "\n",
        "      df_a = pd.DataFrame(data_list, index= id_req1, columns= id_req2)\n",
        "      print(\"data berdasarkan synset\")\n",
        "      print(tabulate(df_a, headers = 'keys', tablefmt = 'psql'))   \n",
        "\n",
        "\n",
        "      data_list = []\n",
        "      for idx, num in enumerate(cleaned1):\n",
        "        a = [myUkur.document_path_similarity(num, angka) for idy, angka in enumerate(cleaned2)]\n",
        "        data_list.append(a)\n",
        "\n",
        "      print(\"\\ndata berdasarkan dokumen\")\n",
        "      df_b = pd.DataFrame(data_list, index= id_req1, columns= id_req2)\n",
        "      print(tabulate(df_b, headers = 'keys', tablefmt = 'psql'))   \n",
        "\n",
        "      word1 = [disambiguate(x) for x in cleaned1]\n",
        "      word1_synset = [[n[1] for n in y] for y in word1]\n",
        "      word1_kata = [[n[0] for n in y] for y in word1]\n",
        "\n",
        "      word2 = [disambiguate(x) for x in cleaned2]\n",
        "      word2_synset = [[n[1] for n in y] for y in word2]\n",
        "      word2_kata = [[n[0] for n in y] for y in word2]\n",
        "\n",
        "      id1 = 7 #data index1\n",
        "      id2 = 19 #data index2\n",
        "      data_list = []\n",
        "      for num in word1_synset[id1]:\n",
        "        a = [(similarity_by_path(num, angka, option= \"wup\")) for angka in word2_synset[id2] if num and angka is not None]\n",
        "        data_list.append(a)\n",
        "\n",
        "      df_sem = pd.DataFrame(data_list, index= word1_kata[id1], columns= word2_kata[id2])\n",
        "      print(\"\\ndata berdasarkan dokumen\")\n",
        "      print(tabulate(df_sem, headers = 'keys', tablefmt = 'psql'))   \n",
        "  except OSError as err:\n",
        "    print(\"OS error: {0}\".format(err))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data berdasarkan synset\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|      |      F01 |      F02 |      F03 |     F04a |     F04b |     F04c |     F04d |     F05a |     F05b |     F06a |     F06b |     F07a |     F07b |     NF01 |    NF02a |    NF02b |    NF02c |    NF02d |    NF02e |    NF03a |    NF03b |    NF03c |    NF03d |    NF03e |    NF03f |    NF04a |    NF04b |    NF05a |    NF05b |    NF05c |    NF05d |    NF05e |    NF05f |    NF06a |    NF06b |    NF06c |    NF06d |    NF06e |    NF06f |    NF06g |    NF06h |    NF07a |    NF07b |    NF07c |    NF07d |    NF07e |    NF07f |    NF07g |    NF08a |    NF08b |    NF08c |    NF08d |    NF08e |    NF08f |    NF08g |    NF09a |    NF09b |    NF10a |    NF10b |    NF11a |    NF11b |    NF11c |    NF11d |    NF11e |    NF11f |    NF11g |    NF12a |    NF12b |    NF12c |    NF12d |    NF12e |    NF12f |\n",
            "|------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|\n",
            "| F01  | 1        | 0.514853 | 0.529138 | 0.408673 | 0.401927 | 0.1292   | 0.130499 | 0.398526 | 0.36371  | 0.265538 | 0.251649 | 0.406463 | 1        | 0.29932  | 0.1292   | 0.124041 | 0.161281 | 0.161281 | 0.161281 | 0.1453   | 0.158277 | 0.17551  | 0.161513 | 0.206916 | 0.162576 | 0.136003 | 0.194444 | 0.163662 | 0.163662 | 0.166837 | 0.166837 | 0.238095 | 0.169785 | 0.166837 | 0.166837 | 0.163492 | 0.154186 | 0.154186 | 0.435884 | 0.288095 | 0.284524 | 0.185884 | 0.185884 | 0.215646 | 0.304932 | 0.304932 | 0.215646 | 0.144506 | 0.139348 | 0.139348 | 0.320805 | 0.165023 | 0.154308 | 0.153912 | 0.153912 | 0.130726 | 0.136678 | 0.146023 | 0.154186 | 0.156411 | 0.327381 | 0.313435 | 0.331293 | 0.162472 | 0.314059 | 0.130779 | 0.156689 | 0.169785 | 0.210884 | 0.169615 | 0.201531 | 0.2089   |\n",
            "| F02  | 0.569003 | 1        | 0.8875   | 0.570635 | 0.564583 | 0.122371 | 0.137401 | 0.561607 | 0.450307 | 0.276885 | 0.2625   | 0.673214 | 0.569003 | 0.484127 | 0.131548 | 0.142609 | 0.157738 | 0.157738 | 0.157738 | 0.140923 | 0.152336 | 0.171383 | 0.159325 | 0.166572 | 0.133681 | 0.163542 | 0.150149 | 0.149856 | 0.151592 | 0.160764 | 0.160764 | 0.333333 | 0.14053  | 0.160764 | 0.162847 | 0.13428  | 0.151497 | 0.1824   | 0.154022 | 0.153472 | 0.150347 | 0.163194 | 0.163194 | 0.177431 | 0.371528 | 0.371528 | 0.177431 | 0.173958 | 0.127728 | 0.12376  | 0.416572 | 0.184925 | 0.149306 | 0.140972 | 0.139236 | 0.133482 | 0.13869  | 0.164241 | 0.178526 | 0.178274 | 0.393056 | 0.169048 | 0.180159 | 0.172822 | 0.179514 | 0.125947 | 0.159375 | 0.147024 | 0.141919 | 0.167762 | 0.172222 | 0.198264 |\n",
            "| F03  | 0.569003 | 0.8875   | 1        | 0.574603 | 0.56994  | 0.127728 | 0.137401 | 0.566964 | 0.448558 | 0.27436  | 0.260417 | 0.673214 | 0.569003 | 0.484127 | 0.136905 | 0.140084 | 0.15377  | 0.15377  | 0.15377  | 0.133482 | 0.158829 | 0.177877 | 0.166766 | 0.162405 | 0.129514 | 0.161458 | 0.158482 | 0.1568   | 0.158536 | 0.167708 | 0.167708 | 0.333333 | 0.145887 | 0.167708 | 0.169792 | 0.116919 | 0.149749 | 0.180652 | 0.171383 | 0.170833 | 0.167708 | 0.170139 | 0.170139 | 0.167014 | 0.378472 | 0.378472 | 0.167014 | 0.171875 | 0.134673 | 0.130704 | 0.399211 | 0.18745  | 0.146181 | 0.139236 | 0.1375   | 0.130357 | 0.135565 | 0.162492 | 0.176778 | 0.17619  | 0.388889 | 0.186409 | 0.186409 | 0.160322 | 0.185764 | 0.124459 | 0.164732 | 0.152381 | 0.15928  | 0.155262 | 0.158829 | 0.180903 |\n",
            "| F04  | 0.265309 | 0.30519  | 0.317548 | 0.641616 | 0.6307   | 0.565958 | 0.504198 | 0.463098 | 0.288817 | 0.475812 | 0.448299 | 0.422886 | 0.265309 | 0.463265 | 0.435006 | 0.368812 | 0.319024 | 0.319024 | 0.319024 | 0.117234 | 0.159189 | 0.165538 | 0.15964  | 0.153092 | 0.129762 | 0.190958 | 0.33699  | 0.145156 | 0.145156 | 0.150397 | 0.150397 | 0.333333 | 0.254906 | 0.150397 | 0.172619 | 0.114322 | 0.128381 | 0.145047 | 0.156465 | 0.153373 | 0.153373 | 0.479365 | 0.479365 | 0.184297 | 0.419841 | 0.419841 | 0.184297 | 0.326276 | 0.316241 | 0.376474 | 0.212621 | 0.246887 | 0.31369  | 0.223871 | 0.223871 | 0.1322   | 0.1322   | 0.157746 | 0.161827 | 0.153231 | 0.231122 | 0.174096 | 0.174096 | 0.14898  | 0.17792  | 0.13447  | 0.270437 | 0.255556 | 0.259867 | 0.131465 | 0.340476 | 0.153633 |\n",
            "| F05  | 0.481786 | 0.568452 | 0.574405 | 0.694805 | 0.669841 | 0.139563 | 0.150559 | 0.838384 | 0.754798 | 0.324525 | 0.250198 | 0.768398 | 0.481786 | 0.500397 | 0.147897 | 0.153327 | 0.16671  | 0.16671  | 0.16671  | 0.126429 | 0.151869 | 0.163413 | 0.163413 | 0.161869 | 0.134167 | 0.235198 | 0.175675 | 0.138968 | 0.144365 | 0.150833 | 0.150833 | 0.333333 | 0.132348 | 0.150833 | 0.159722 | 0.110808 | 0.136468 | 0.162024 | 0.154802 | 0.155    | 0.155    | 0.175    | 0.175    | 0.155952 | 0.428175 | 0.428175 | 0.155952 | 0.176865 | 0.144127 | 0.140952 | 0.511869 | 0.178337 | 0.157222 | 0.145245 | 0.142348 | 0.126627 | 0.126627 | 0.158968 | 0.179286 | 0.171429 | 0.520238 | 0.168968 | 0.168968 | 0.152222 | 0.17298  | 0.125189 | 0.150833 | 0.142222 | 0.135884 | 0.157619 | 0.164444 | 0.183099 |\n",
            "| F06  | 0.243908 | 0.254514 | 0.259871 | 0.660494 | 0.586004 | 0.454464 | 0.354861 | 0.376448 | 0.318346 | 0.861111 | 0.816667 | 0.342939 | 0.243908 | 0.292857 | 0.397321 | 0.296329 | 0.311607 | 0.311607 | 0.311607 | 0.13254  | 0.1688   | 0.181151 | 0.1688   | 0.257788 | 0.222917 | 0.291361 | 0.308723 | 0.154514 | 0.154514 | 0.192266 | 0.192266 | 0.333333 | 0.252579 | 0.194792 | 0.214236 | 0.122822 | 0.14867  | 0.199806 | 0.160574 | 0.18185  | 0.18185  | 0.43428  | 0.43428  | 0.189732 | 0.330114 | 0.330114 | 0.189732 | 0.321223 | 0.29187  | 0.288745 | 0.173516 | 0.197817 | 0.30561  | 0.260458 | 0.168015 | 0.13805  | 0.13805  | 0.278626 | 0.278626 | 0.278514 | 0.277232 | 0.179221 | 0.179221 | 0.164038 | 0.271036 | 0.146181 | 0.345988 | 0.336468 | 0.253526 | 0.148413 | 0.379678 | 0.261468 |\n",
            "| F07  | 0.656852 | 0.541455 | 0.548122 | 0.524134 | 0.485053 | 0.123785 | 0.130957 | 0.515749 | 0.443271 | 0.306945 | 0.247463 | 0.740327 | 0.656852 | 0.339021 | 0.129606 | 0.129789 | 0.160558 | 0.160558 | 0.160558 | 0.141537 | 0.15788  | 0.16526  | 0.157436 | 0.195899 | 0.155948 | 0.14786  | 0.178307 | 0.149367 | 0.151034 | 0.16651  | 0.16651  | 0.269841 | 0.149873 | 0.16651  | 0.16651  | 0.142997 | 0.142346 | 0.159569 | 0.28696  | 0.225875 | 0.224209 | 0.168733 | 0.168733 | 0.186085 | 0.278256 | 0.278256 | 0.186085 | 0.155796 | 0.132068 | 0.129952 | 0.302066 | 0.166242 | 0.14746  | 0.144923 | 0.143256 | 0.129683 | 0.13246  | 0.148537 | 0.156156 | 0.163468 | 0.36627  | 0.236484 | 0.24828  | 0.165159 | 0.248677 | 0.125043 | 0.16127  | 0.155608 | 0.173261 | 0.16709  | 0.178571 | 0.186219 |\n",
            "| NF01 | 0.265774 | 0.372321 | 0.370238 | 0.37436  | 0.369246 | 0.229167 | 0.232842 | 0.369246 | 0.247864 | 0.178378 | 0.167708 | 0.374454 | 0.265774 | 1        | 0.253472 | 0.253675 | 0.37619  | 0.37619  | 0.37619  | 0.349256 | 0.158375 | 0.162344 | 0.159425 | 0.170585 | 0.134578 | 0.273264 | 0.35291  | 0.147227 | 0.145491 | 0.176096 | 0.176096 | 0.225    | 0.245644 | 0.176096 | 0.176096 | 0.131408 | 0.137943 | 0.172467 | 0.149161 | 0.165679 | 0.179072 | 0.303725 | 0.309975 | 0.209028 | 0.303725 | 0.309975 | 0.209028 | 0.175149 | 0.129915 | 0.125947 | 0.293353 | 0.174992 | 0.146875 | 0.139385 | 0.139385 | 0.13502  | 0.13502  | 0.166068 | 0.173211 | 0.167708 | 0.272024 | 0.16305  | 0.193353 | 0.174256 | 0.18621  | 0.126448 | 0.284524 | 0.247917 | 0.246591 | 0.177381 | 0.313194 | 0.170833 |\n",
            "| NF02 | 0.161142 | 0.163719 | 0.160261 | 0.218455 | 0.283617 | 0.30822  | 0.315167 | 0.188379 | 0.152549 | 0.215479 | 0.279847 | 0.171882 | 0.161142 | 0.423583 | 0.381434 | 0.38532  | 0.686111 | 0.688333 | 0.682778 | 0.214371 | 0.16383  | 0.161563 | 0.158308 | 0.164711 | 0.118058 | 0.30445  | 0.357738 | 0.134274 | 0.132656 | 0.15638  | 0.15638  | 0.2375   | 0.206494 | 0.15638  | 0.169079 | 0.137531 | 0.145352 | 0.153031 | 0.152755 | 0.142775 | 0.170666 | 0.367491 | 0.367491 | 0.19263  | 0.306692 | 0.306692 | 0.19263  | 0.282823 | 0.249237 | 0.249237 | 0.164853 | 0.172331 | 0.28254  | 0.170918 | 0.170269 | 0.139824 | 0.139824 | 0.16012  | 0.16012  | 0.221684 | 0.159269 | 0.160493 | 0.179084 | 0.164541 | 0.171372 | 0.150286 | 0.219133 | 0.209921 | 0.207035 | 0.174348 | 0.279365 | 0.164853 |\n",
            "| NF03 | 0.147469 | 0.157082 | 0.158939 | 0.167215 | 0.162824 | 0.112742 | 0.121436 | 0.160986 | 0.127237 | 0.190667 | 0.184709 | 0.167335 | 0.147469 | 0.195265 | 0.126553 | 0.129221 | 0.140651 | 0.140651 | 0.140651 | 0.333785 | 0.427852 | 0.385251 | 0.382927 | 0.650169 | 0.579492 | 0.270675 | 0.183419 | 0.225074 | 0.190998 | 0.156059 | 0.156059 | 0.291667 | 0.126156 | 0.157374 | 0.160109 | 0.111119 | 0.118377 | 0.156539 | 0.138488 | 0.181372 | 0.182688 | 0.138053 | 0.138053 | 0.139536 | 0.146512 | 0.146512 | 0.139536 | 0.181202 | 0.118693 | 0.115476 | 0.255829 | 0.249294 | 0.227508 | 0.222608 | 0.221355 | 0.121159 | 0.123352 | 0.17564  | 0.177311 | 0.181226 | 0.276086 | 0.154397 | 0.194163 | 0.179056 | 0.245324 | 0.107634 | 0.24096  | 0.221355 | 0.130018 | 0.140376 | 0.136028 | 0.236572 |\n",
            "| NF04 | 0.15257  | 0.168536 | 0.176494 | 0.216597 | 0.24951  | 0.182448 | 0.195567 | 0.24951  | 0.130628 | 0.235967 | 0.26818  | 0.188469 | 0.15257  | 0.37575  | 0.218021 | 0.224063 | 0.416575 | 0.416575 | 0.416575 | 0.190008 | 0.169514 | 0.167647 | 0.166176 | 0.316457 | 0.284479 | 0.703965 | 0.72112  | 0.139029 | 0.135761 | 0.185109 | 0.185109 | 0.25     | 0.125663 | 0.185109 | 0.196755 | 0.113527 | 0.126379 | 0.181116 | 0.15257  | 0.288961 | 0.299045 | 0.210786 | 0.210786 | 0.146244 | 0.209736 | 0.209736 | 0.146244 | 0.235127 | 0.188842 | 0.184316 | 0.169517 | 0.185693 | 0.200868 | 0.145663 | 0.145663 | 0.130464 | 0.130464 | 0.20894  | 0.20894  | 0.204688 | 0.259384 | 0.175397 | 0.214613 | 0.171968 | 0.243091 | 0.130364 | 0.210273 | 0.129159 | 0.133342 | 0.140548 | 0.158942 | 0.138356 |\n",
            "| NF05 | 0.15963  | 0.167627 | 0.178655 | 0.169716 | 0.164098 | 0.160992 | 0.117567 | 0.160842 | 0.137015 | 0.171846 | 0.164208 | 0.165898 | 0.15963  | 0.215499 | 0.168923 | 0.118799 | 0.146617 | 0.146617 | 0.146617 | 0.177577 | 0.153088 | 0.163325 | 0.152211 | 0.218441 | 0.179221 | 0.150178 | 0.146201 | 0.618672 | 0.620532 | 0.575844 | 0.575844 | 0.368571 | 0.394272 | 0.332712 | 0.332712 | 0.118666 | 0.150296 | 0.207337 | 0.172704 | 0.218905 | 0.211159 | 0.3632   | 0.3632   | 0.286218 | 0.325001 | 0.325001 | 0.286218 | 0.152326 | 0.252509 | 0.24919  | 0.186886 | 0.183878 | 0.140874 | 0.183522 | 0.139264 | 0.123977 | 0.150585 | 0.220848 | 0.220848 | 0.206907 | 0.163134 | 0.172097 | 0.172097 | 0.151971 | 0.180368 | 0.121117 | 0.275006 | 0.283943 | 0.282532 | 0.146305 | 0.192442 | 0.148392 |\n",
            "| NF06 | 0.236212 | 0.176795 | 0.179719 | 0.182502 | 0.179033 | 0.116215 | 0.121244 | 0.17661  | 0.119041 | 0.198477 | 0.194929 | 0.175733 | 0.236212 | 0.180309 | 0.148379 | 0.147122 | 0.152134 | 0.152134 | 0.152134 | 0.147678 | 0.149518 | 0.157847 | 0.148015 | 0.209275 | 0.185019 | 0.195624 | 0.152971 | 0.219755 | 0.199287 | 0.316913 | 0.316913 | 0.189881 | 0.134367 | 0.482178 | 0.50846  | 0.201237 | 0.326827 | 0.460614 | 0.391485 | 0.457061 | 0.445359 | 0.185841 | 0.185841 | 0.194716 | 0.185443 | 0.185443 | 0.194716 | 0.164546 | 0.169367 | 0.163623 | 0.19511  | 0.183661 | 0.130601 | 0.125519 | 0.125519 | 0.127719 | 0.139766 | 0.185102 | 0.185102 | 0.18831  | 0.206142 | 0.200895 | 0.207474 | 0.167498 | 0.247887 | 0.109227 | 0.16453  | 0.136759 | 0.146687 | 0.138244 | 0.143467 | 0.141729 |\n",
            "| NF07 | 0.226341 | 0.222377 | 0.223214 | 0.266845 | 0.31561  | 0.272641 | 0.247599 | 0.239685 | 0.197952 | 0.220549 | 0.26634  | 0.226237 | 0.226341 | 0.300024 | 0.276148 | 0.247136 | 0.260408 | 0.260408 | 0.260408 | 0.145507 | 0.204185 | 0.2065   | 0.202291 | 0.175882 | 0.128664 | 0.173066 | 0.259173 | 0.239348 | 0.244334 | 0.299854 | 0.299854 | 0.246667 | 0.207652 | 0.26272  | 0.272597 | 0.144204 | 0.147044 | 0.160364 | 0.167148 | 0.158179 | 0.158179 | 0.73548  | 0.733207 | 0.589628 | 0.737374 | 0.735101 | 0.589628 | 0.333494 | 0.321098 | 0.319334 | 0.268585 | 0.183311 | 0.256129 | 0.215961 | 0.214638 | 0.136332 | 0.136332 | 0.17297  | 0.171515 | 0.17287  | 0.22381  | 0.177333 | 0.184278 | 0.221914 | 0.187963 | 0.145717 | 0.220723 | 0.209149 | 0.209768 | 0.180688 | 0.332848 | 0.220172 |\n",
            "| NF08 | 0.201148 | 0.207784 | 0.205861 | 0.238641 | 0.279462 | 0.294798 | 0.30126  | 0.261147 | 0.22288  | 0.230982 | 0.267448 | 0.207895 | 0.201148 | 0.186301 | 0.197489 | 0.196354 | 0.218189 | 0.218189 | 0.218189 | 0.120409 | 0.139783 | 0.141781 | 0.140732 | 0.317752 | 0.291332 | 0.155451 | 0.211708 | 0.156978 | 0.209493 | 0.170957 | 0.170957 | 0.247917 | 0.13492  | 0.169354 | 0.183884 | 0.119308 | 0.11783  | 0.130618 | 0.130864 | 0.130359 | 0.130359 | 0.279429 | 0.24866  | 0.204398 | 0.326528 | 0.295758 | 0.204398 | 0.21496  | 0.262608 | 0.327384 | 0.504217 | 0.58257  | 0.47553  | 0.676603 | 0.633761 | 0.184388 | 0.184388 | 0.140266 | 0.143685 | 0.137966 | 0.18025  | 0.142647 | 0.148523 | 0.155069 | 0.154398 | 0.149258 | 0.341299 | 0.331996 | 0.127103 | 0.155617 | 0.22174  | 0.374858 |\n",
            "| NF09 | 0.130906 | 0.135776 | 0.132205 | 0.148186 | 0.135828 | 0.109586 | 0.127948 | 0.131689 | 0.12013  | 0.145635 | 0.133277 | 0.131689 | 0.130906 | 0.143197 | 0.115708 | 0.132483 | 0.133792 | 0.133792 | 0.133792 | 0.123182 | 0.117749 | 0.129654 | 0.113384 | 0.12132  | 0.100455 | 0.123645 | 0.129427 | 0.181411 | 0.168713 | 0.116606 | 0.116606 | 0.2      | 0.125685 | 0.116606 | 0.116606 | 0.107876 | 0.136688 | 0.144109 | 0.138276 | 0.134572 | 0.127151 | 0.133277 | 0.133277 | 0.137812 | 0.133277 | 0.133277 | 0.137812 | 0.128407 | 0.111173 | 0.109586 | 0.150232 | 0.144109 | 0.249268 | 0.24145  | 0.24145  | 0.873016 | 0.87013  | 0.123701 | 0.123701 | 0.133277 | 0.130499 | 0.129257 | 0.131241 | 0.118591 | 0.126422 | 0.105217 | 0.140416 | 0.241053 | 0.239971 | 0.126541 | 0.130391 | 0.13424  |\n",
            "| NF10 | 0.161515 | 0.193333 | 0.193333 | 0.206667 | 0.213333 | 0.13     | 0.141587 | 0.213333 | 0.163333 | 0.356667 | 0.356667 | 0.195556 | 0.161515 | 0.198333 | 0.138571 | 0.147937 | 0.173333 | 0.173333 | 0.173333 | 0.146515 | 0.174127 | 0.180476 | 0.180476 | 0.325556 | 0.274848 | 0.333571 | 0.173333 | 0.315238 | 0.315238 | 0.288182 | 0.288182 | 0.208333 | 0.143182 | 0.221515 | 0.231905 | 0.12342  | 0.150087 | 0.231905 | 0.150087 | 0.206753 | 0.206753 | 0.176667 | 0.193333 | 0.158889 | 0.183333 | 0.2      | 0.158889 | 0.198333 | 0.135    | 0.13     | 0.2      | 0.195238 | 0.168333 | 0.157071 | 0.157071 | 0.130556 | 0.130556 | 0.857143 | 1        | 0.338889 | 0.333571 | 0.170238 | 0.170238 | 0.186667 | 0.330556 | 0.32     | 0.238182 | 0.211364 | 0.209848 | 0.153333 | 0.165238 | 0.175556 |\n",
            "| NF11 | 0.252249 | 0.207729 | 0.209513 | 0.224034 | 0.223401 | 0.127743 | 0.133395 | 0.221616 | 0.187322 | 0.218872 | 0.216057 | 0.247075 | 0.252249 | 0.214881 | 0.136806 | 0.135874 | 0.193466 | 0.193466 | 0.193466 | 0.142351 | 0.181926 | 0.186998 | 0.181687 | 0.334091 | 0.301902 | 0.208059 | 0.22185  | 0.144806 | 0.145438 | 0.184155 | 0.184155 | 0.29     | 0.155571 | 0.184155 | 0.190056 | 0.134416 | 0.130093 | 0.176382 | 0.208102 | 0.236425 | 0.235643 | 0.165863 | 0.167425 | 0.181277 | 0.191905 | 0.193467 | 0.181277 | 0.192434 | 0.140352 | 0.132765 | 0.241222 | 0.194833 | 0.148938 | 0.143157 | 0.142526 | 0.12809  | 0.129392 | 0.234715 | 0.233897 | 0.332791 | 0.575955 | 0.402791 | 0.478212 | 0.268543 | 0.492039 | 0.197911 | 0.163508 | 0.138113 | 0.151665 | 0.205596 | 0.172162 | 0.171283 |\n",
            "| NF12 | 0.192556 | 0.186239 | 0.172236 | 0.167804 | 0.160629 | 0.176475 | 0.137732 | 0.159354 | 0.153903 | 0.266583 | 0.25702  | 0.176545 | 0.192556 | 0.255248 | 0.181836 | 0.139461 | 0.162277 | 0.162277 | 0.162277 | 0.151721 | 0.145703 | 0.151358 | 0.145748 | 0.272449 | 0.234288 | 0.161212 | 0.150468 | 0.161914 | 0.175085 | 0.18545  | 0.18545  | 0.238265 | 0.211936 | 0.154838 | 0.154838 | 0.154442 | 0.140364 | 0.15206  | 0.158825 | 0.149862 | 0.148007 | 0.249277 | 0.249277 | 0.302353 | 0.200935 | 0.200935 | 0.302353 | 0.149052 | 0.121954 | 0.120424 | 0.377409 | 0.255374 | 0.24667  | 0.339622 | 0.243581 | 0.133518 | 0.165264 | 0.156718 | 0.159694 | 0.154767 | 0.174986 | 0.160142 | 0.208456 | 0.222001 | 0.181633 | 0.125306 | 0.558998 | 0.559081 | 0.364262 | 0.428982 | 0.484449 | 0.489633 |\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "\n",
            "data berdasarkan dokumen\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "|      |      F01 |      F02 |      F03 |     F04a |     F04b |     F04c |     F04d |     F05a |     F05b |     F06a |     F06b |     F07a |     F07b |     NF01 |    NF02a |    NF02b |    NF02c |    NF02d |    NF02e |    NF03a |    NF03b |    NF03c |    NF03d |    NF03e |    NF03f |    NF04a |    NF04b |    NF05a |    NF05b |    NF05c |    NF05d |    NF05e |    NF05f |    NF06a |    NF06b |    NF06c |    NF06d |    NF06e |    NF06f |    NF06g |    NF06h |    NF07a |    NF07b |    NF07c |    NF07d |    NF07e |    NF07f |    NF07g |    NF08a |    NF08b |    NF08c |    NF08d |    NF08e |    NF08f |    NF08g |    NF09a |    NF09b |    NF10a |    NF10b |    NF11a |    NF11b |    NF11c |    NF11d |    NF11e |    NF11f |    NF11g |    NF12a |    NF12b |    NF12c |    NF12d |    NF12e |    NF12f |\n",
            "|------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|\n",
            "| F01  | 1        | 0.541928 | 0.54907  | 0.406321 | 0.397591 | 0.130572 | 0.128245 | 0.457681 | 0.416141 | 0.271069 | 0.257874 | 0.38153  | 1        | 0.282547 | 0.13173  | 0.125182 | 0.149237 | 0.146856 | 0.152809 | 0.148597 | 0.15934  | 0.176846 | 0.164133 | 0.185418 | 0.151937 | 0.128024 | 0.187963 | 0.150106 | 0.149685 | 0.156037 | 0.149192 | 0.285714 | 0.165845 | 0.151196 | 0.151196 | 0.227579 | 0.158343 | 0.147926 | 0.508567 | 0.301548 | 0.288095 | 0.180164 | 0.182664 | 0.20326  | 0.279645 | 0.282145 | 0.20326  | 0.165309 | 0.137729 | 0.144674 | 0.304868 | 0.155604 | 0.134618 | 0.138558 | 0.137236 | 0.127836 | 0.136368 | 0.148055 | 0.157851 | 0.146387 | 0.287958 | 0.303477 | 0.312174 | 0.178016 | 0.294698 | 0.173723 | 0.158329 | 0.168989 | 0.219728 | 0.170392 | 0.202849 | 0.221437 |\n",
            "| F02  | 0.541928 | 1        | 0.8875   | 0.539683 | 0.5313   | 0.113616 | 0.126488 | 0.591603 | 0.472772 | 0.289368 | 0.275926 | 0.618973 | 0.541928 | 0.428224 | 0.131052 | 0.143725 | 0.150836 | 0.148455 | 0.154408 | 0.155283 | 0.163946 | 0.182358 | 0.170615 | 0.159974 | 0.133531 | 0.178968 | 0.14785  | 0.147326 | 0.147202 | 0.162723 | 0.16942  | 0.333333 | 0.147408 | 0.160584 | 0.162535 | 0.19214  | 0.156999 | 0.200922 | 0.149382 | 0.175347 | 0.175504 | 0.156597 | 0.159097 | 0.164707 | 0.305764 | 0.308264 | 0.164707 | 0.218924 | 0.127025 | 0.115121 | 0.364263 | 0.184129 | 0.134838 | 0.133449 | 0.130531 | 0.132055 | 0.140215 | 0.173073 | 0.18593  | 0.184375 | 0.320438 | 0.166931 | 0.170067 | 0.206108 | 0.181887 | 0.171307 | 0.174019 | 0.158999 | 0.156356 | 0.172869 | 0.175694 | 0.207928 |\n",
            "| F03  | 0.54907  | 0.8875   | 1        | 0.545918 | 0.53823  | 0.125124 | 0.12996  | 0.598533 | 0.471898 | 0.288106 | 0.274884 | 0.618973 | 0.54907  | 0.427183 | 0.140873 | 0.142463 | 0.142333 | 0.139952 | 0.145904 | 0.144122 | 0.173145 | 0.191558 | 0.180288 | 0.159655 | 0.133408 | 0.177927 | 0.159532 | 0.153389 | 0.153265 | 0.177307 | 0.179836 | 0.333333 | 0.154372 | 0.169612 | 0.171562 | 0.148737 | 0.156124 | 0.200048 | 0.175424 | 0.197917 | 0.195759 | 0.167768 | 0.170268 | 0.157515 | 0.314792 | 0.317292 | 0.157515 | 0.217882 | 0.139757 | 0.132482 | 0.346902 | 0.187376 | 0.129109 | 0.132812 | 0.129861 | 0.128409 | 0.136569 | 0.172199 | 0.185056 | 0.183333 | 0.317143 | 0.187186 | 0.180357 | 0.187358 | 0.188252 | 0.170563 | 0.179758 | 0.164739 | 0.183212 | 0.149953 | 0.160995 | 0.1761   |\n",
            "| F04  | 0.336991 | 0.43878  | 0.446944 | 0.773933 | 0.761778 | 0.782979 | 0.752099 | 0.636311 | 0.427146 | 0.565287 | 0.522761 | 0.518411 | 0.336991 | 0.524368 | 0.578614 | 0.545517 | 0.290269 | 0.287888 | 0.29384  | 0.136945 | 0.183325 | 0.192213 | 0.18355  | 0.15895  | 0.135037 | 0.207681 | 0.311352 | 0.149452 | 0.147071 | 0.166151 | 0.168056 | 0.333333 | 0.29412  | 0.160956 | 0.182976 | 0.150911 | 0.14544  | 0.182246 | 0.167965 | 0.189187 | 0.188591 | 0.433492 | 0.435992 | 0.199887 | 0.401133 | 0.403633 | 0.199887 | 0.440916 | 0.376375 | 0.549348 | 0.253213 | 0.287621 | 0.359497 | 0.259095 | 0.25528  | 0.141298 | 0.14477  | 0.18554  | 0.18758  | 0.177012 | 0.249986 | 0.185659 | 0.183576 | 0.192545 | 0.191969 | 0.200568 | 0.297154 | 0.27384  | 0.310886 | 0.138616 | 0.375099 | 0.161413 |\n",
            "| F05  | 0.440156 | 0.567634 | 0.573289 | 0.698444 | 0.674206 | 0.167951 | 0.180393 | 0.919192 | 0.877399 | 0.372519 | 0.298176 | 0.739358 | 0.440156 | 0.434821 | 0.1758   | 0.187775 | 0.167369 | 0.164988 | 0.17094  | 0.140595 | 0.177879 | 0.185437 | 0.185437 | 0.164049 | 0.140915 | 0.270352 | 0.187705 | 0.138093 | 0.140791 | 0.159147 | 0.164454 | 0.333333 | 0.141922 | 0.155341 | 0.171452 | 0.145682 | 0.128948 | 0.177044 | 0.156865 | 0.1875   | 0.189405 | 0.176448 | 0.178948 | 0.146658 | 0.34748  | 0.34998  | 0.146658 | 0.255099 | 0.172262 | 0.162017 | 0.454099 | 0.189199 | 0.173519 | 0.149279 | 0.153461 | 0.129716 | 0.131799 | 0.180437 | 0.19631  | 0.183333 | 0.433571 | 0.178333 | 0.176746 | 0.192778 | 0.187416 | 0.195928 | 0.172327 | 0.157109 | 0.155839 | 0.155298 | 0.170979 | 0.179512 |\n",
            "| F06  | 0.263195 | 0.266567 | 0.27123  | 0.677816 | 0.618796 | 0.616121 | 0.466319 | 0.390555 | 0.375245 | 0.930556 | 0.908333 | 0.342944 | 0.263195 | 0.291173 | 0.555804 | 0.371974 | 0.285285 | 0.282904 | 0.288856 | 0.140133 | 0.18313  | 0.19502  | 0.18313  | 0.241655 | 0.215344 | 0.295234 | 0.281897 | 0.151287 | 0.149898 | 0.203752 | 0.209824 | 0.333333 | 0.292956 | 0.20184  | 0.221563 | 0.155161 | 0.155585 | 0.237403 | 0.159603 | 0.209377 | 0.206302 | 0.394283 | 0.396783 | 0.185937 | 0.299602 | 0.302102 | 0.185937 | 0.4245   | 0.361213 | 0.357335 | 0.178452 | 0.193642 | 0.355456 | 0.264302 | 0.16386  | 0.14009  | 0.143562 | 0.320979 | 0.320979 | 0.312868 | 0.263398 | 0.178499 | 0.171034 | 0.189658 | 0.287138 | 0.206424 | 0.369375 | 0.358539 | 0.307716 | 0.145602 | 0.413053 | 0.319181 |\n",
            "| F07  | 0.828426 | 0.667603 | 0.670936 | 0.605296 | 0.559278 | 0.131833 | 0.135419 | 0.650732 | 0.580763 | 0.355799 | 0.271684 | 0.870164 | 0.828426 | 0.362814 | 0.144168 | 0.14426  | 0.162592 | 0.160211 | 0.166163 | 0.158566 | 0.181718 | 0.188741 | 0.179115 | 0.196204 | 0.16554  | 0.175715 | 0.187257 | 0.152326 | 0.152167 | 0.183374 | 0.183404 | 0.301587 | 0.160694 | 0.174366 | 0.175477 | 0.217332 | 0.152423 | 0.189507 | 0.434105 | 0.300438 | 0.286509 | 0.176152 | 0.178652 | 0.189754 | 0.269803 | 0.272303 | 0.189754 | 0.212819 | 0.146987 | 0.142952 | 0.312218 | 0.178756 | 0.139868 | 0.141542 | 0.138777 | 0.133889 | 0.140833 | 0.166332 | 0.175856 | 0.179353 | 0.364583 | 0.275881 | 0.278828 | 0.209663 | 0.296792 | 0.173633 | 0.180522 | 0.168054 | 0.200916 | 0.180866 | 0.193783 | 0.215795 |\n",
            "| NF01 | 0.282547 | 0.428224 | 0.427183 | 0.398178 | 0.39324  | 0.292163 | 0.294    | 0.452764 | 0.296551 | 0.187205 | 0.179092 | 0.374107 | 0.282547 | 1        | 0.362847 | 0.362949 | 0.385488 | 0.383107 | 0.389059 | 0.460342 | 0.175418 | 0.177402 | 0.175942 | 0.161784 | 0.130875 | 0.291989 | 0.390344 | 0.144801 | 0.141552 | 0.179    | 0.180905 | 0.279167 | 0.285322 | 0.173805 | 0.177215 | 0.169871 | 0.129686 | 0.182265 | 0.143628 | 0.184506 | 0.203425 | 0.299839 | 0.305464 | 0.209276 | 0.297241 | 0.302866 | 0.209276 | 0.226463 | 0.144323 | 0.137048 | 0.292611 | 0.176447 | 0.1372   | 0.133849 | 0.134238 | 0.140625 | 0.142708 | 0.176487 | 0.185772 | 0.175918 | 0.259524 | 0.166446 | 0.189013 | 0.202207 | 0.189831 | 0.177807 | 0.304198 | 0.267045 | 0.300081 | 0.179266 | 0.347569 | 0.176957 |\n",
            "| NF02 | 0.169006 | 0.165565 | 0.163836 | 0.224987 | 0.314711 | 0.480499 | 0.483972 | 0.189994 | 0.164171 | 0.227977 | 0.326828 | 0.16977  | 0.169006 | 0.509262 | 0.690717 | 0.69266  | 0.843056 | 0.844167 | 0.841389 | 0.302126 | 0.174931 | 0.173797 | 0.168995 | 0.155236 | 0.118603 | 0.351258 | 0.408256 | 0.136363 | 0.133173 | 0.152476 | 0.150214 | 0.285417 | 0.267413 | 0.151801 | 0.167039 | 0.172932 | 0.13339  | 0.14477  | 0.145425 | 0.156387 | 0.206166 | 0.373388 | 0.375888 | 0.202863 | 0.297534 | 0.300034 | 0.202863 | 0.391412 | 0.339896 | 0.337582 | 0.162389 | 0.170865 | 0.350866 | 0.162016 | 0.167963 | 0.146499 | 0.148583 | 0.170298 | 0.170298 | 0.279294 | 0.158206 | 0.160901 | 0.178679 | 0.183461 | 0.161579 | 0.208476 | 0.259597 | 0.248047 | 0.280303 | 0.177749 | 0.344544 | 0.167022 |\n",
            "| NF03 | 0.185809 | 0.171919 | 0.170764 | 0.191431 | 0.189235 | 0.130329 | 0.136909 | 0.182647 | 0.14596  | 0.259222 | 0.256243 | 0.178782 | 0.185809 | 0.231784 | 0.145221 | 0.149531 | 0.146856 | 0.144475 | 0.150427 | 0.581178 | 0.713926 | 0.692625 | 0.691464 | 0.791751 | 0.789746 | 0.332361 | 0.224403 | 0.287096 | 0.223762 | 0.179977 | 0.187607 | 0.3125   | 0.146411 | 0.183251 | 0.187792 | 0.180559 | 0.140439 | 0.21577  | 0.169393 | 0.261519 | 0.256026 | 0.153789 | 0.156289 | 0.152081 | 0.158911 | 0.161411 | 0.152081 | 0.332268 | 0.137322 | 0.131548 | 0.278683 | 0.342504 | 0.334587 | 0.257832 | 0.307701 | 0.130655 | 0.137307 | 0.258058 | 0.258893 | 0.25478  | 0.33963  | 0.183449 | 0.251769 | 0.286403 | 0.35669  | 0.172865 | 0.274137 | 0.261443 | 0.166795 | 0.154414 | 0.15978  | 0.368286 |\n",
            "| NF04 | 0.173507 | 0.171247 | 0.179393 | 0.240526 | 0.316507 | 0.306849 | 0.329034 | 0.28666  | 0.143369 | 0.302965 | 0.388516 | 0.18972  | 0.173507 | 0.374912 | 0.338177 | 0.362031 | 0.458883 | 0.456502 | 0.462454 | 0.279528 | 0.189876 | 0.187157 | 0.183922 | 0.356167 | 0.340346 | 0.851982 | 0.86056  | 0.137197 | 0.132677 | 0.194503 | 0.202133 | 0.291667 | 0.137468 | 0.190931 | 0.208421 | 0.147041 | 0.117167 | 0.209876 | 0.165774 | 0.353571 | 0.349523 | 0.232715 | 0.235215 | 0.146736 | 0.229213 | 0.231713 | 0.146736 | 0.395341 | 0.308707 | 0.299301 | 0.168265 | 0.186299 | 0.299508 | 0.142444 | 0.149815 | 0.13296  | 0.134644 | 0.278637 | 0.278637 | 0.265916 | 0.288759 | 0.187004 | 0.250535 | 0.20265  | 0.291916 | 0.198515 | 0.249949 | 0.142839 | 0.157901 | 0.135188 | 0.180629 | 0.141268 |\n",
            "| NF05 | 0.173438 | 0.176276 | 0.185262 | 0.185737 | 0.177571 | 0.250635 | 0.121779 | 0.174242 | 0.152634 | 0.203516 | 0.193447 | 0.169608 | 0.173438 | 0.251675 | 0.299739 | 0.13182  | 0.137228 | 0.134847 | 0.1408   | 0.274259 | 0.168488 | 0.182496 | 0.16805  | 0.2492   | 0.229712 | 0.187912 | 0.151077 | 0.757484 | 0.758414 | 0.787922 | 0.787922 | 0.684286 | 0.625707 | 0.406634 | 0.405523 | 0.153083 | 0.200148 | 0.353668 | 0.191709 | 0.321119 | 0.296651 | 0.418396 | 0.420669 | 0.338942 | 0.361418 | 0.363691 | 0.338942 | 0.208108 | 0.337564 | 0.332928 | 0.202545 | 0.204042 | 0.137566 | 0.234585 | 0.140465 | 0.130907 | 0.177544 | 0.30971  | 0.30971  | 0.283414 | 0.170495 | 0.175863 | 0.169283 | 0.184571 | 0.203147 | 0.168892 | 0.361312 | 0.382448 | 0.444599 | 0.144548 | 0.246915 | 0.164474 |\n",
            "| NF06 | 0.350929 | 0.190109 | 0.191571 | 0.205026 | 0.203292 | 0.140399 | 0.139938 | 0.196412 | 0.140473 | 0.222387 | 0.220612 | 0.187073 | 0.350929 | 0.190303 | 0.218634 | 0.214037 | 0.164162 | 0.161781 | 0.167734 | 0.206279 | 0.175156 | 0.188209 | 0.174404 | 0.211086 | 0.190724 | 0.224449 | 0.183122 | 0.262365 | 0.229404 | 0.481833 | 0.437677 | 0.261607 | 0.157019 | 0.741089 | 0.75423  | 0.600619 | 0.663414 | 0.730307 | 0.695743 | 0.653531 | 0.660179 | 0.263893 | 0.266393 | 0.309348 | 0.261114 | 0.263614 | 0.309348 | 0.226717 | 0.308493 | 0.302645 | 0.209782 | 0.195997 | 0.136332 | 0.130157 | 0.131892 | 0.13959  | 0.158114 | 0.212789 | 0.212789 | 0.210107 | 0.209718 | 0.260864 | 0.260508 | 0.213957 | 0.316305 | 0.173661 | 0.179374 | 0.159536 | 0.195963 | 0.162178 | 0.173916 | 0.181976 |\n",
            "| NF07 | 0.280518 | 0.319522 | 0.314732 | 0.329256 | 0.40721  | 0.464446 | 0.389425 | 0.353261 | 0.270206 | 0.254719 | 0.340114 | 0.260688 | 0.280518 | 0.377691 | 0.499185 | 0.401346 | 0.267279 | 0.264898 | 0.27085  | 0.160551 | 0.273878 | 0.277417 | 0.272931 | 0.177822 | 0.145681 | 0.198735 | 0.262721 | 0.240681 | 0.244496 | 0.447185 | 0.406637 | 0.29     | 0.272278 | 0.308146 | 0.320584 | 0.217935 | 0.142967 | 0.182034 | 0.161154 | 0.185201 | 0.186828 | 0.86774  | 0.866604 | 0.794814 | 0.868687 | 0.867551 | 0.794814 | 0.666747 | 0.517692 | 0.513834 | 0.337045 | 0.198373 | 0.34235  | 0.260262 | 0.254003 | 0.140223 | 0.142868 | 0.206485 | 0.200758 | 0.194054 | 0.251389 | 0.1845   | 0.188568 | 0.360957 | 0.203241 | 0.206192 | 0.274307 | 0.254915 | 0.286789 | 0.209987 | 0.485869 | 0.349173 |\n",
            "| NF08 | 0.313839 | 0.352404 | 0.346234 | 0.35682  | 0.434374 | 0.480732 | 0.483963 | 0.472835 | 0.436837 | 0.344603 | 0.41998  | 0.291695 | 0.313839 | 0.244788 | 0.320967 | 0.320399 | 0.244894 | 0.242513 | 0.248465 | 0.148002 | 0.173225 | 0.17601  | 0.175485 | 0.332328 | 0.322187 | 0.188812 | 0.235814 | 0.198131 | 0.272007 | 0.344569 | 0.284342 | 0.290625 | 0.151938 | 0.255788 | 0.273053 | 0.205487 | 0.119629 | 0.161341 | 0.138646 | 0.170179 | 0.172917 | 0.392274 | 0.339389 | 0.360816 | 0.459573 | 0.406689 | 0.360816 | 0.385258 | 0.631304 | 0.663692 | 0.698537 | 0.730061 | 0.737765 | 0.838301 | 0.81688  | 0.23267  | 0.234753 | 0.174419 | 0.181842 | 0.16565  | 0.224133 | 0.161006 | 0.166077 | 0.244201 | 0.186458 | 0.374629 | 0.377594 | 0.363394 | 0.162718 | 0.193185 | 0.33536  | 0.598888 |\n",
            "| NF09 | 0.133792 | 0.137233 | 0.133885 | 0.144501 | 0.136621 | 0.112581 | 0.128706 | 0.131491 | 0.124787 | 0.143687 | 0.135524 | 0.13023  | 0.133792 | 0.139109 | 0.123992 | 0.141638 | 0.131352 | 0.130076 | 0.133052 | 0.13555  | 0.123319 | 0.133438 | 0.118636 | 0.117706 | 0.100185 | 0.128291 | 0.128847 | 0.173595 | 0.161185 | 0.115013 | 0.115302 | 0.2      | 0.129338 | 0.117311 | 0.118422 | 0.131319 | 0.166558 | 0.16134  | 0.146023 | 0.148635 | 0.141783 | 0.133603 | 0.134793 | 0.133532 | 0.132214 | 0.133404 | 0.133532 | 0.145156 | 0.116433 | 0.11101  | 0.146619 | 0.141187 | 0.328999 | 0.247845 | 0.238072 | 0.936508 | 0.935065 | 0.127128 | 0.127128 | 0.131202 | 0.126938 | 0.129774 | 0.127974 | 0.130277 | 0.12753  | 0.130386 | 0.144584 | 0.245413 | 0.273319 | 0.127589 | 0.133449 | 0.13339  |\n",
            "| NF10 | 0.157851 | 0.18593  | 0.185056 | 0.202143 | 0.205476 | 0.13053  | 0.142817 | 0.206156 | 0.169286 | 0.339841 | 0.339841 | 0.176717 | 0.157851 | 0.185772 | 0.14158  | 0.154921 | 0.152028 | 0.149647 | 0.155599 | 0.145373 | 0.17246  | 0.17881  | 0.17881  | 0.265393 | 0.231023 | 0.306022 | 0.160234 | 0.267134 | 0.264819 | 0.269091 | 0.289924 | 0.270833 | 0.140801 | 0.201783 | 0.213571 | 0.14921  | 0.135758 | 0.239762 | 0.133674 | 0.210996 | 0.211809 | 0.163851 | 0.178851 | 0.139563 | 0.170929 | 0.185929 | 0.139563 | 0.229722 | 0.135556 | 0.123333 | 0.190373 | 0.177145 | 0.146987 | 0.136334 | 0.139524 | 0.12702  | 0.129104 | 0.857143 | 1        | 0.332702 | 0.278791 | 0.162996 | 0.153673 | 0.198447 | 0.302715 | 0.493333 | 0.229888 | 0.206901 | 0.218182 | 0.138577 | 0.162516 | 0.165876 |\n",
            "| NF11 | 0.352995 | 0.312892 | 0.316909 | 0.292969 | 0.289082 | 0.146163 | 0.148989 | 0.343631 | 0.355566 | 0.279512 | 0.273938 | 0.334103 | 0.352995 | 0.269494 | 0.157292 | 0.156826 | 0.249879 | 0.247498 | 0.253451 | 0.179806 | 0.259416 | 0.269452 | 0.261082 | 0.370994 | 0.357653 | 0.253657 | 0.250012 | 0.150357 | 0.148909 | 0.207474 | 0.211324 | 0.311667 | 0.227902 | 0.199855 | 0.207091 | 0.192208 | 0.146297 | 0.225691 | 0.287533 | 0.322379 | 0.306115 | 0.183824 | 0.187106 | 0.21116  | 0.237262 | 0.240543 | 0.21116  | 0.351773 | 0.170176 | 0.153883 | 0.333186 | 0.24206  | 0.145302 | 0.14056  | 0.141501 | 0.13253  | 0.137811 | 0.384024 | 0.378615 | 0.666395 | 0.787977 | 0.641872 | 0.69281  | 0.634271 | 0.74602  | 0.598955 | 0.180847 | 0.157237 | 0.190118 | 0.328592 | 0.207113 | 0.234253 |\n",
            "| NF12 | 0.225529 | 0.210828 | 0.203827 | 0.202355 | 0.191114 | 0.262345 | 0.180473 | 0.197024 | 0.193618 | 0.293952 | 0.281517 | 0.198243 | 0.225529 | 0.315719 | 0.309172 | 0.204651 | 0.170679 | 0.168298 | 0.174251 | 0.184492 | 0.179796 | 0.18679  | 0.183985 | 0.31934  | 0.303079 | 0.221454 | 0.164475 | 0.195173 | 0.203081 | 0.278558 | 0.300017 | 0.285799 | 0.279493 | 0.16853  | 0.169641 | 0.223055 | 0.168396 | 0.197062 | 0.188044 | 0.19755  | 0.192853 | 0.301424 | 0.303924 | 0.359113 | 0.239753 | 0.242253 | 0.359113 | 0.209447 | 0.141929 | 0.138188 | 0.407455 | 0.353877 | 0.33762  | 0.36692  | 0.315923 | 0.149232 | 0.239179 | 0.206137 | 0.215958 | 0.175955 | 0.184775 | 0.179377 | 0.253707 | 0.331834 | 0.207714 | 0.173764 | 0.779499 | 0.779541 | 0.682131 | 0.714491 | 0.678733 | 0.744816 |\n",
            "+------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
            "\n",
            "data berdasarkan dokumen\n",
            "+------------+---------------+---------------+-----------------+------------+------------+\n",
            "|            |   performance |   requirement |   transparently |    defined |     server |\n",
            "|------------+---------------+---------------+-----------------+------------+------------|\n",
            "| color      |      0.266667 |      0.266667 |        0        |   0.2      |   0.285714 |\n",
            "| search     |      0.555556 |      0.526316 |        0        |   0.142857 |   0.111111 |\n",
            "| among      |    nan        |    nan        |      nan        | nan        | nan        |\n",
            "| various    |      0        |      0        |        0        |   0.4      |   0        |\n",
            "| collection |      0.285714 |      0.285714 |        0        |   0.2      |   0.142857 |\n",
            "| defined    |      0.166667 |      0.166667 |        0.4      |   0.333333 |   0.153846 |\n",
            "| abc        |      0.315789 |      0.315789 |        0        |   0.133333 |   0.105263 |\n",
            "| paint      |      0.25     |      0.25     |        0        |   0.181818 |   0.421053 |\n",
            "| processed  |      0.153846 |      0.153846 |        0.333333 |   0.285714 |   0.142857 |\n",
            "| subsecond  |    nan        |    nan        |      nan        | nan        | nan        |\n",
            "| time       |      0.533333 |      0.533333 |        0        |   0.181818 |   0.133333 |\n",
            "| server     |      0.125    |      0.125    |        0        |   0.153846 |   0.909091 |\n",
            "+------------+---------------+---------------+-----------------+------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhca6OCQym2_"
      },
      "source": [
        "import xlsxwriter\n",
        "import pandas as pd\n",
        "dfs  = {\n",
        "          'tabel_synset' : df_a, \n",
        "          'tabel_dokumen' : df_b,\n",
        "          'tabel_per_kata' : df_sem,\n",
        "        } \n",
        "\n",
        "writer = pd.ExcelWriter('/content/mydrive/MyDrive/dataset/wsd/data_wsd_alternatif.xlsx')\n",
        "\n",
        "for name,dataframe in dfs.items():\n",
        "    dataframe.to_excel(writer,name,index=False)\n",
        "\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ1wNq5VyIRw"
      },
      "source": [
        "### Manual Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSZuAmKzSN4J",
        "outputId": "a182437b-e7ce-4bcc-8b9a-6b3e39ece647"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "#define array of actual values\n",
        "y_actual = [\n",
        "1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\n",
        "0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\n",
        "]\n",
        "\n",
        "#define array of predicted values\n",
        "y_predicted = [\n",
        "1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\n",
        "0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\n",
        "]\n",
        "\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true= y_actual, y_pred= y_predicted).ravel()\n",
        "\n",
        "print(\"false positif : \",fp)\n",
        "print(\"false negative : \",fn)\n",
        "print(\"true positive : \", tp) \n",
        "print(\"true negative : \", tn)\n",
        "\n",
        "print(\"akurasi\", metrics.accuracy_score(y_true= y_actual, y_pred= y_predicted))\n",
        "print(\"recall\", metrics.recall_score(y_true= y_actual, y_pred= y_predicted))\n",
        "print(\"presion\", metrics.precision_score(y_true= y_actual, y_pred= y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "false positif :  94\n",
            "false negative :  261\n",
            "true positive :  17\n",
            "true negative :  2958\n",
            "akurasi 0.8933933933933934\n",
            "recall 0.06115107913669065\n",
            "presion 0.15315315315315314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ9rg4RMSLzN"
      },
      "source": [
        "### Another method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyQP_cmYUArF"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import pandas as pd\n",
        "\n",
        "def convert_tag(tag):\n",
        "    \"\"\"Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\"\"\"\n",
        "    \n",
        "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
        "    try:\n",
        "        return tag_dict[tag[0]]\n",
        "    except KeyError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def doc_to_synsets(doc):\n",
        "    \"\"\"\n",
        "    Returns a list of synsets in document.\n",
        "\n",
        "    Tokenizes and tags the words in the document doc.\n",
        "    Then finds the first synset for each word/tag combination.\n",
        "    If a synset is not found for that combination it is skipped.\n",
        "\n",
        "    Args:\n",
        "        doc: string to be converted\n",
        "\n",
        "    Returns:\n",
        "        list of synsets\n",
        "\n",
        "    Example:\n",
        "        doc_to_synsets('Fish are nvqjp friends.')\n",
        "        Out: [Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]\n",
        "    \"\"\"\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    pos = nltk.pos_tag(tokens)\n",
        "    tags = [tag[1] for tag in pos]\n",
        "    wntag = [convert_tag(tag) for tag in tags]\n",
        "    ans = list(zip(tokens,wntag))\n",
        "    sets = [wn.synsets(x,y) for x,y in ans]\n",
        "    final = [val[0] for val in sets if len(val) > 0]\n",
        "    \n",
        "    return final\n",
        "\n",
        "\n",
        "def similarity_score(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculate the normalized similarity score of s1 onto s2\n",
        "\n",
        "    For each synset in s1, finds the synset in s2 with the largest similarity value.\n",
        "    Sum of all of the largest similarity values and normalize this value by dividing it by the\n",
        "    number of largest similarity values found.\n",
        "\n",
        "    Args:\n",
        "        s1, s2: list of synsets from doc_to_synsets\n",
        "\n",
        "    Returns:\n",
        "        normalized similarity score of s1 onto s2\n",
        "\n",
        "    Example:\n",
        "        synsets1 = doc_to_synsets('I like cats')\n",
        "        synsets2 = doc_to_synsets('I like dogs')\n",
        "        similarity_score(synsets1, synsets2)\n",
        "        Out: 0.73333333333333339\n",
        "    \"\"\"\n",
        "    s =[]\n",
        "    for i1 in s1:\n",
        "        r = []\n",
        "        scores = [x for x in [i1.path_similarity(i2) for i2 in s2] if x is not None]\n",
        "        if scores:\n",
        "            s.append(max(scores))\n",
        "    return sum(s)/len(s)\n",
        "\n",
        "\n",
        "def document_path_similarity(doc1, doc2):\n",
        "    \"\"\"Finds the symmetrical similarity between doc1 and doc2\"\"\"\n",
        "\n",
        "    synsets1 = doc_to_synsets(doc1)\n",
        "    synsets2 = doc_to_synsets(doc2)\n",
        "\n",
        "    return (similarity_score(synsets1, synsets2) + similarity_score(synsets2, synsets1)) / 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TTvPzyKUCpf",
        "outputId": "72b590ac-61b8-48fb-fd76-75306a0a25ad"
      },
      "source": [
        "doc_to_synsets('Fish are nvqjp friends.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CrETK83UQKx",
        "outputId": "85fd3cfa-31bc-4a7a-eb82-29b8d3d1ed24"
      },
      "source": [
        "synsets1 = doc_to_synsets('I like cats')\n",
        "synsets2 = doc_to_synsets('I like dogs')\n",
        "similarity_score(synsets1, synsets2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlSGL6jaUnR5",
        "outputId": "c9987286-cfa0-4bcb-e2da-e089f474906f"
      },
      "source": [
        "doc1 = \"I like you\"\n",
        "doc2 = \"I love you\"\n",
        "document_path_similarity(doc1, doc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWHqlZYGXT-p",
        "outputId": "eb242b50-9df0-41ab-f989-d78e8f34eb3c"
      },
      "source": [
        "def test_document_path_similarity():\n",
        "    doc1 = 'This is a function to test document_path_similarity.'\n",
        "    doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
        "    and similarity_score is correct!'\n",
        "    return document_path_similarity(doc1, doc2)\n",
        "test_document_path_similarity()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.554265873015873"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRaLdClXXZx5"
      },
      "source": [
        "def most_similar_docs():\n",
        "    paraphrases = cleaned1\n",
        "    paraphrases['similarity_score'] = paraphrases.apply(lambda x:document_path_similarity(x['D1'], x['D2']), axis=1)\n",
        "    return (paraphrases.sort_values('similarity_score', ascending=False).iloc[0]['D1'], paraphrases.sort_values('similarity_score', ascending=False).iloc[0]['D2'], paraphrases.sort_values('similarity_score', ascending=False).iloc[0]['similarity_score'])\n",
        "most_similar_docs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l4hCW-EXmRk"
      },
      "source": [
        "def label_accuracy():\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    paraphrases['similarity_score'] = paraphrases.apply(lambda x:document_path_similarity(x['D1'], x['D2']), axis=1)\n",
        "    paraphrases['predicted'] = np.where(paraphrases['similarity_score'] > 0.75, 1, 0)\n",
        "    \n",
        "    return accuracy_score(paraphrases['Quality'], paraphrases['predicted'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}